version: '3.9'

x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"

networks:
  bev_osint:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16

volumes:
  postgres_data:
  neo4j_data:
  redis_data:
  elasticsearch_data:
  influxdb_data:
  kafka_data:
  zookeeper_data:
  rabbitmq_data:
  tor_data:
  intelowl_postgres_data:
  intelowl_static_data:
  # Phase 7 Volumes
  dm_crawler_data:
  crypto_intel_data:
  reputation_data:
  economics_data:
  # Phase 8 Volumes
  tactical_intel_data:
  defense_automation_data:
  opsec_data:
  intel_fusion_data:
  # Predictive Cache Volumes
  predictive_cache_data:
  predictive_cache_models:
  predictive_cache_cache:
  # Phase 9 Volumes
  autonomous_data:
  adaptive_learning_data:
  resource_manager_data:
  knowledge_evolution_data:
  ml_models:
  # Vector Database Volumes
  qdrant_data:
  weaviate_data:
  qdrant_snapshots:
  weaviate_backups:
  # Context Compression Volumes
  context_compression_data:
  # Edge Computing Volumes
  edge_models_us_east:
  edge_models_us_west:
  edge_models_eu_central:
  edge_models_asia_pacific:
  edge_cache_data:
  edge_logs_data:
  compression_cache:
  # Extended Reasoning Volumes
  extended_reasoning_data:
  extended_reasoning_cache:
  extended_reasoning_models:
  # Health Monitoring Volumes
  health_monitoring_data:
  health_metrics_data:
  # Proxy Management Volumes
  proxy_pool_data:
  proxy_metrics_data:
  # Auto-Recovery Volumes
  recovery_logs_data:
  recovery_state_data:
  # Chaos Engineering Volumes
  chaos_logs_data:
  chaos_scenarios_data:
  logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /home/starlord/Bev/logs

services:
  # PostgreSQL with pgvector
  postgres:
    image: pgvector/pgvector:pg16
    container_name: bev_postgres
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_MULTIPLE_DATABASES: osint,intelowl,breach_data,crypto_analysis
      POSTGRES_HOST_AUTH_METHOD: md5
      SHARED_PRELOAD_LIBRARIES: pg_stat_statements,pgvector
      MAX_CONNECTIONS: 500
      SHARED_BUFFERS: 2GB
      EFFECTIVE_CACHE_SIZE: 6GB
      MAINTENANCE_WORK_MEM: 512MB
      WORK_MEM: 32MB
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init_scripts/postgres_init.sql:/docker-entrypoint-initdb.d/init.sql:ro
      - logs:/var/log/postgresql
    ports:
      - "5432:5432"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.2
    logging: *default-logging
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Neo4j Graph Database
  neo4j:
    image: neo4j:5.14-enterprise
    container_name: bev_neo4j
    restart: always
    environment:
      NEO4J_AUTH: ${NEO4J_USER}/${NEO4J_PASSWORD}
      NEO4J_ACCEPT_LICENSE_AGREEMENT: yes
      NEO4J_server_memory_heap_initial__size: 2G
      NEO4J_server_memory_heap_max__size: 4G
      NEO4J_server_memory_pagecache__size: 2G
      NEO4J_dbms_security_procedures_unrestricted: apoc.*,gds.*
      NEO4J_dbms_security_procedures_allowlist: apoc.*,gds.*
      NEO4J_apoc_export_file_enabled: true
      NEO4J_apoc_import_file_enabled: true
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
      NEO4J_dbms_connector_bolt_listen__address: 0.0.0.0:7687
      NEO4J_dbms_connector_http_listen__address: 0.0.0.0:7474
      NEO4J_dbms_connector_https_listen__address: 0.0.0.0:7473
    volumes:
      - neo4j_data:/data
      - ./init_scripts/neo4j_init.cypher:/import/init.cypher:ro
      - logs:/logs
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
      - "7473:7473"  # HTTPS
    networks:
      bev_osint:
        ipv4_address: 172.30.0.3
    logging: *default-logging

  # Redis Cluster Node 1
  redis-node-1:
    image: redis:7-alpine
    container_name: bev_redis_1
    restart: always
    command: >
      redis-server
      --port 7001
      --cluster-enabled yes
      --cluster-config-file nodes.conf
      --cluster-node-timeout 5000
      --appendonly yes
      --requirepass ${REDIS_PASSWORD}
      --masterauth ${REDIS_PASSWORD}
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
    volumes:
      - ./redis/node1:/data
      - logs:/var/log/redis
    ports:
      - "7001:7001"
      - "17001:17001"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.4
    logging: *default-logging

  # Redis Cluster Node 2
  redis-node-2:
    image: redis:7-alpine
    container_name: bev_redis_2
    restart: always
    command: >
      redis-server
      --port 7002
      --cluster-enabled yes
      --cluster-config-file nodes.conf
      --cluster-node-timeout 5000
      --appendonly yes
      --requirepass ${REDIS_PASSWORD}
      --masterauth ${REDIS_PASSWORD}
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
    volumes:
      - ./redis/node2:/data
      - logs:/var/log/redis
    ports:
      - "7002:7002"
      - "17002:17002"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.5
    logging: *default-logging

  # Redis Cluster Node 3
  redis-node-3:
    image: redis:7-alpine
    container_name: bev_redis_3
    restart: always
    command: >
      redis-server
      --port 7003
      --cluster-enabled yes
      --cluster-config-file nodes.conf
      --cluster-node-timeout 5000
      --appendonly yes
      --requirepass ${REDIS_PASSWORD}
      --masterauth ${REDIS_PASSWORD}
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
    volumes:
      - ./redis/node3:/data
      - logs:/var/log/redis
    ports:
      - "7003:7003"
      - "17003:17003"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.6
    logging: *default-logging

  # Redis Standalone for IntelOwl
  redis:
    image: redis:7-alpine
    container_name: bev_redis_standalone
    restart: always
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 1gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.7
    logging: *default-logging

  # RabbitMQ Node 1
  rabbitmq-1:
    image: rabbitmq:3-management
    container_name: bev_rabbitmq_1
    hostname: rabbitmq-1
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_ERLANG_COOKIE: BevRabbitClusterCookie2024
      RABBITMQ_NODENAME: rabbit@rabbitmq-1
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: -rabbit disk_free_limit 2147483648
    volumes:
      - ./rabbitmq/node1:/var/lib/rabbitmq
      - logs:/var/log/rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.8
    logging: *default-logging

  # RabbitMQ Node 2
  rabbitmq-2:
    image: rabbitmq:3-management
    container_name: bev_rabbitmq_2
    hostname: rabbitmq-2
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_ERLANG_COOKIE: BevRabbitClusterCookie2024
      RABBITMQ_NODENAME: rabbit@rabbitmq-2
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: -rabbit disk_free_limit 2147483648
    volumes:
      - ./rabbitmq/node2:/var/lib/rabbitmq
      - logs:/var/log/rabbitmq
    ports:
      - "5673:5672"
      - "15673:15672"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.9
    logging: *default-logging

  # RabbitMQ Node 3
  rabbitmq-3:
    image: rabbitmq:3-management
    container_name: bev_rabbitmq_3
    hostname: rabbitmq-3
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_ERLANG_COOKIE: BevRabbitClusterCookie2024
      RABBITMQ_NODENAME: rabbit@rabbitmq-3
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: -rabbit disk_free_limit 2147483648
    volumes:
      - ./rabbitmq/node3:/var/lib/rabbitmq
      - logs:/var/log/rabbitmq
    ports:
      - "5674:5672"
      - "15674:15672"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.10
    logging: *default-logging

  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: bev_zookeeper
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_MAX_CLIENT_CNXNS: 100
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - ./zookeeper/log:/var/lib/zookeeper/log
      - logs:/var/log/zookeeper
    ports:
      - "2181:2181"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.11
    logging: *default-logging

  # Kafka Broker 1
  kafka-1:
    image: confluentinc/cp-kafka:7.5.0
    container_name: bev_kafka_1
    restart: always
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092,EXTERNAL://0.0.0.0:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
    volumes:
      - ./kafka/broker1:/var/lib/kafka/data
      - logs:/var/log/kafka
    ports:
      - "19092:19092"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.12
    logging: *default-logging

  # Kafka Broker 2
  kafka-2:
    image: confluentinc/cp-kafka:7.5.0
    container_name: bev_kafka_2
    restart: always
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:9092,EXTERNAL://0.0.0.0:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
    volumes:
      - ./kafka/broker2:/var/lib/kafka/data
      - logs:/var/log/kafka
    ports:
      - "29092:29092"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.13
    logging: *default-logging

  # Kafka Broker 3
  kafka-3:
    image: confluentinc/cp-kafka:7.5.0
    container_name: bev_kafka_3
    restart: always
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:9092,EXTERNAL://0.0.0.0:39092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
    volumes:
      - ./kafka/broker3:/var/lib/kafka/data
      - logs:/var/log/kafka
    ports:
      - "39092:39092"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.14
    logging: *default-logging

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: bev_elasticsearch
    restart: always
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - cluster.name=bev-osint-cluster
      - bootstrap.memory_lock=true
      - indices.query.bool.max_clause_count=10000
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - logs:/usr/share/elasticsearch/logs
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.15
    logging: *default-logging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 30s
      timeout: 10s
      retries: 5

  # InfluxDB
  influxdb:
    image: influxdb:2.7
    container_name: bev_influxdb
    restart: always
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: bev
      DOCKER_INFLUXDB_INIT_PASSWORD: BevMetrics2024
      DOCKER_INFLUXDB_INIT_ORG: bev-osint
      DOCKER_INFLUXDB_INIT_BUCKET: metrics
      DOCKER_INFLUXDB_INIT_RETENTION: 30d
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_DATA_QUERY_LOG_ENABLED: false
      INFLUXDB_HTTP_LOG_ENABLED: false
    volumes:
      - influxdb_data:/var/lib/influxdb2
      - ./influxdb/config:/etc/influxdb2
      - logs:/var/log/influxdb
    ports:
      - "8086:8086"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.16
    logging: *default-logging

  # Tor SOCKS5 Proxy with Control Port
  tor:
    image: dperson/torproxy:latest
    container_name: bev_tor
    restart: always
    environment:
      TORUSER: bev
      PASSWORD: ${TOR_CONTROL_PASSWORD}
      TOR_NewCircuitPeriod: 600
      TOR_MaxCircuitDirtiness: 600
      TOR_NumEntryGuards: 6
      TOR_ControlPort: 9051
      TOR_HashedControlPassword: 16:872860B76453A77D60CA2BB8C1A7042072093276A3D701AD684053EC4C
    volumes:
      - tor_data:/var/lib/tor
      - ./tor/torrc:/etc/tor/torrc:ro
      - logs:/var/log/tor
    ports:
      - "9050:9050"  # SOCKS5
      - "9051:9051"  # Control
      - "8118:8118"  # Privoxy HTTP
    networks:
      bev_osint:
        ipv4_address: 172.30.0.17
    logging: *default-logging

  # IntelOwl Postgres
  intelowl-postgres:
    image: postgres:16-alpine
    container_name: bev_intelowl_postgres
    restart: always
    environment:
      POSTGRES_DB: ${INTELOWL_POSTGRES_DB}
      POSTGRES_USER: ${INTELOWL_POSTGRES_USER}
      POSTGRES_PASSWORD: ${INTELOWL_POSTGRES_PASSWORD}
    volumes:
      - intelowl_postgres_data:/var/lib/postgresql/data
      - ./intelowl/sql_init:/docker-entrypoint-initdb.d
    networks:
      bev_osint:
        ipv4_address: 172.30.0.18
    logging: *default-logging

  # IntelOwl Celery Beat
  intelowl-celery-beat:
    image: intelowlproject/intelowl:v5.2.0
    container_name: bev_intelowl_celery_beat
    restart: always
    depends_on:
      - intelowl-postgres
      - redis
      - rabbitmq-1
    environment:
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
      - POSTGRES_HOST=${INTELOWL_POSTGRES_HOST}
      - POSTGRES_DB=${INTELOWL_POSTGRES_DB}
      - POSTGRES_USER=${INTELOWL_POSTGRES_USER}
      - POSTGRES_PASSWORD=${INTELOWL_POSTGRES_PASSWORD}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - CELERY_BROKER_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-1:5672
      - DISABLE_AUTHENTICATION_CHECKS=True
      - DISABLE_PERMISSIONS_CHECKS=True
      - DISABLE_THROTTLING=True
    volumes:
      - ./intelowl/custom_analyzers:/opt/deploy/intelowl/custom_analyzers:ro
      - ./intelowl/custom_connectors:/opt/deploy/intelowl/custom_connectors:ro
      - /home/starlord/Bev/src:/opt/bev_src:ro
      - intelowl_static_data:/opt/deploy/static
      - logs:/var/log/intelowl
    command: celery -A intel_owl beat -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    networks:
      bev_osint:
        ipv4_address: 172.30.0.19
    logging: *default-logging

  # IntelOwl Celery Worker
  intelowl-celery-worker:
    image: intelowlproject/intelowl:v5.2.0
    container_name: bev_intelowl_celery_worker
    restart: always
    depends_on:
      - intelowl-postgres
      - redis
      - rabbitmq-1
    environment:
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
      - POSTGRES_HOST=${INTELOWL_POSTGRES_HOST}
      - POSTGRES_DB=${INTELOWL_POSTGRES_DB}
      - POSTGRES_USER=${INTELOWL_POSTGRES_USER}
      - POSTGRES_PASSWORD=${INTELOWL_POSTGRES_PASSWORD}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - CELERY_BROKER_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-1:5672
      - DISABLE_AUTHENTICATION_CHECKS=True
      - DISABLE_PERMISSIONS_CHECKS=True
      - DISABLE_THROTTLING=True
      - HTTP_PROXY=socks5://tor:9050
      - HTTPS_PROXY=socks5://tor:9050
      - TOR_PROXY=${TOR_PROXY}
      - NEO4J_URI=${NEO4J_URI}
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - DEHASHED_API_KEY=${DEHASHED_API_KEY}
      - DEHASHED_EMAIL=${DEHASHED_EMAIL}
      - SNUSBASE_API_KEY=${SNUSBASE_API_KEY}
      - WELEAKINFO_API_KEY=${WELEAKINFO_API_KEY}
      - SHODAN_API_KEY=${SHODAN_API_KEY}
      - VIRUSTOTAL_API_KEY=${VIRUSTOTAL_API_KEY}
    volumes:
      - ./intelowl/custom_analyzers:/opt/deploy/intelowl/custom_analyzers:ro
      - ./intelowl/custom_connectors:/opt/deploy/intelowl/custom_connectors:ro
      - /home/starlord/Bev/src:/opt/bev_src:ro
      - intelowl_static_data:/opt/deploy/static
      - logs:/var/log/intelowl
    command: celery -A intel_owl worker -l info -c ${WORKERS} --max-tasks-per-child 100
    networks:
      bev_osint:
        ipv4_address: 172.30.0.20
    logging: *default-logging
    deploy:
      replicas: 4
      resources:
        limits:
          memory: 4G

  # IntelOwl Django/API
  intelowl-django:
    image: intelowlproject/intelowl:v5.2.0
    container_name: bev_intelowl_django
    restart: always
    depends_on:
      - intelowl-postgres
      - redis
      - rabbitmq-1
    environment:
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
      - POSTGRES_HOST=${INTELOWL_POSTGRES_HOST}
      - POSTGRES_DB=${INTELOWL_POSTGRES_DB}
      - POSTGRES_USER=${INTELOWL_POSTGRES_USER}
      - POSTGRES_PASSWORD=${INTELOWL_POSTGRES_PASSWORD}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - CELERY_BROKER_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-1:5672
      - DISABLE_AUTHENTICATION_CHECKS=True
      - DISABLE_PERMISSIONS_CHECKS=True
      - DISABLE_THROTTLING=True
      - DJANGO_ALLOWED_HOSTS=${DJANGO_ALLOWED_HOSTS}
      - DJANGO_DEBUG=${DJANGO_DEBUG}
      - DEFAULT_FROM_EMAIL=bev-osint@localhost
      - DEFAULT_EMAIL=bev@localhost
    volumes:
      - ./intelowl/custom_analyzers:/opt/deploy/intelowl/custom_analyzers:ro
      - ./intelowl/custom_connectors:/opt/deploy/intelowl/custom_connectors:ro
      - /home/starlord/Bev/src:/opt/bev_src:ro
      - intelowl_static_data:/opt/deploy/static
      - ./intelowl/dark_theme.css:/opt/deploy/static/css/custom.css:ro
      - logs:/var/log/intelowl
    command: >
      sh -c "
      python manage.py migrate &&
      python manage.py collectstatic --noinput &&
      python manage.py createsuperuser --noinput --username admin --email admin@localhost || true &&
      gunicorn intel_owl.wsgi:application --bind 0.0.0.0:8000 --workers ${WORKERS} --threads ${THREADS_PER_WORKER} --timeout ${REQUEST_TIMEOUT} --access-logfile - --error-logfile -"
    ports:
      - "8000:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.21
    logging: *default-logging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # IntelOwl Nginx with Cytoscape
  intelowl-nginx:
    image: nginx:alpine
    container_name: bev_intelowl_nginx
    restart: always
    depends_on:
      - intelowl-django
    volumes:
      - ./intelowl/nginx.conf:/etc/nginx/nginx.conf:ro
      - intelowl_static_data:/usr/share/nginx/html/static:ro
      - ./cytoscape:/usr/share/nginx/html/cytoscape:ro
      - ./intelowl/dark_theme.css:/usr/share/nginx/html/static/css/dark_theme.css:ro
      - logs:/var/log/nginx
    ports:
      - "80:80"
      - "443:443"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.22
    logging: *default-logging
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Cytoscape.js Server (Custom Node.js App)
  cytoscape-server:
    build:
      context: ./cytoscape
      dockerfile: Dockerfile
    container_name: bev_cytoscape_server
    restart: always
    depends_on:
      - neo4j
      - postgres
    environment:
      NODE_ENV: production
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      POSTGRES_URI: ${POSTGRES_URI}
      PORT: 3000
    volumes:
      - ./cytoscape:/app
      - logs:/app/logs
    ports:
      - "3000:3000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.23
    logging: *default-logging

  # =============================================================
  # PHASE 7 - ALTERNATIVE MARKET INTELLIGENCE
  # =============================================================

  # Decentralized Market Crawler with Tor
  dm-crawler:
    build:
      context: ./phase7/dm-crawler
      dockerfile: Dockerfile
    container_name: bev_dm_crawler
    restart: always
    depends_on:
      - tor
      - postgres
      - kafka-1
      - redis
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/2
      TOR_PROXY: ${TOR_PROXY}
      HTTP_PROXY: socks5://tor:9050
      HTTPS_PROXY: socks5://tor:9050
      CRAWLER_WORKERS: 8
      RATE_LIMIT_REQUESTS: 100
      RATE_LIMIT_PERIOD: 3600
      LOG_LEVEL: INFO
      DM_SITES_CONFIG: /app/config/dm_sites.json
      USER_AGENTS_CONFIG: /app/config/user_agents.json
    volumes:
      - dm_crawler_data:/app/data
      - ./phase7/dm-crawler/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8001:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.24
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # Cryptocurrency Transaction Analyzer
  crypto-intel:
    build:
      context: ./phase7/crypto-intel
      dockerfile: Dockerfile
    container_name: bev_crypto_intel
    restart: always
    depends_on:
      - postgres
      - elasticsearch
      - kafka-1
      - redis
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      ELASTICSEARCH_URL: http://elasticsearch:9200
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/3
      BLOCKCHAIN_API_KEYS: ${BLOCKCHAIN_API_KEYS}
      CHAINALYSIS_API_KEY: ${CHAINALYSIS_API_KEY}
      ELLIPTIC_API_KEY: ${ELLIPTIC_API_KEY}
      ANALYSIS_WORKERS: 4
      BLOCKCHAIN_NETWORKS: bitcoin,ethereum,monero,zcash,dash
      LOG_LEVEL: INFO
    volumes:
      - crypto_intel_data:/app/data
      - ./phase7/crypto-intel/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8002:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.25
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '1.5'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # Vendor Reputation Analyzer
  reputation-analyzer:
    build:
      context: ./phase7/reputation-analyzer
      dockerfile: Dockerfile
    container_name: bev_reputation_analyzer
    restart: always
    depends_on:
      - postgres
      - neo4j
      - elasticsearch
      - kafka-1
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      ELASTICSEARCH_URL: http://elasticsearch:9200
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      ML_MODEL_PATH: /app/models/reputation_model.pkl
      SENTIMENT_MODEL_PATH: /app/models/sentiment_model.pkl
      REPUTATION_THRESHOLD: 0.7
      ANALYSIS_BATCH_SIZE: 100
      LOG_LEVEL: INFO
    volumes:
      - reputation_data:/app/data
      - ml_models:/app/models
      - ./phase7/reputation-analyzer/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8003:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.26
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # Market Economics and Prediction Processor
  economics-processor:
    build:
      context: ./phase7/economics-processor
      dockerfile: Dockerfile
    container_name: bev_economics_processor
    restart: always
    depends_on:
      - postgres
      - influxdb
      - kafka-1
      - redis
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      INFLUXDB_URL: http://influxdb:8086
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_ORG: bev-osint
      INFLUXDB_BUCKET: economics
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/4
      PREDICTION_MODEL_PATH: /app/models/market_prediction.pkl
      ECONOMIC_INDICATORS_API: ${ECONOMIC_INDICATORS_API}
      PREDICTION_HORIZON_DAYS: 30
      MODEL_RETRAIN_INTERVAL: 24
      LOG_LEVEL: INFO
    volumes:
      - economics_data:/app/data
      - ml_models:/app/models
      - ./phase7/economics-processor/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8004:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.27
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 6G
          cpus: '2.0'
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # =============================================================
  # PHASE 8 - ADVANCED SECURITY OPERATIONS
  # =============================================================

  # Tactical Intelligence Processor
  tactical-intel:
    build:
      context: ./phase8/tactical-intel
      dockerfile: Dockerfile
    container_name: bev_tactical_intel
    restart: always
    depends_on:
      - postgres
      - neo4j
      - elasticsearch
      - kafka-1
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      ELASTICSEARCH_URL: http://elasticsearch:9200
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      THREAT_INTEL_FEEDS: ${THREAT_INTEL_FEEDS}
      MITRE_ATT_CK_URL: https://attack.mitre.org/data/enterprise-attack.json
      INTELLIGENCE_CONFIDENCE_THRESHOLD: 0.8
      TACTICAL_ANALYSIS_INTERVAL: 300
      LOG_LEVEL: INFO
    volumes:
      - tactical_intel_data:/app/data
      - ./phase8/tactical-intel/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8005:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.28
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # Automated Threat Response
  defense-automation:
    build:
      context: ./phase8/defense-automation
      dockerfile: Dockerfile
    container_name: bev_defense_automation
    restart: always
    depends_on:
      - postgres
      - kafka-1
      - redis
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/5
      DEFENSE_RULES_CONFIG: /app/config/defense_rules.json
      RESPONSE_AUTOMATION_LEVEL: 2
      MAX_AUTOMATED_RESPONSES: 10
      COOLDOWN_PERIOD: 300
      THREAT_SCORE_THRESHOLD: 0.75
      NOTIFICATION_WEBHOOKS: ${NOTIFICATION_WEBHOOKS}
      LOG_LEVEL: INFO
    volumes:
      - defense_automation_data:/app/data
      - ./phase8/defense-automation/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8006:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.29
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # Operational Security Enforcement
  opsec-enforcer:
    build:
      context: ./phase8/opsec-enforcer
      dockerfile: Dockerfile
    container_name: bev_opsec_enforcer
    restart: always
    depends_on:
      - postgres
      - kafka-1
      - redis
      - tor
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/6
      TOR_PROXY: ${TOR_PROXY}
      OPSEC_RULES_CONFIG: /app/config/opsec_rules.json
      PRIVACY_LEVEL: HIGH
      VPN_ROTATION_INTERVAL: 1800
      METADATA_STRIPPING: true
      TRAFFIC_ANALYSIS_THRESHOLD: 0.9
      OPERATIONAL_COMPARTMENTS: ${OPERATIONAL_COMPARTMENTS}
      LOG_LEVEL: INFO
    volumes:
      - opsec_data:/app/data
      - ./phase8/opsec-enforcer/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8007:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.30
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # Multi-Source Intelligence Correlation
  intel-fusion:
    build:
      context: ./phase8/intel-fusion
      dockerfile: Dockerfile
    container_name: bev_intel_fusion
    restart: always
    depends_on:
      - postgres
      - neo4j
      - elasticsearch
      - kafka-1
      - redis
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      ELASTICSEARCH_URL: http://elasticsearch:9200
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/7
      FUSION_MODEL_PATH: /app/models/intel_fusion.pkl
      CORRELATION_THRESHOLD: 0.8
      FUSION_CONFIDENCE_THRESHOLD: 0.85
      MAX_CORRELATION_DEPTH: 5
      TEMPORAL_CORRELATION_WINDOW: 3600
      LOG_LEVEL: INFO
    volumes:
      - intel_fusion_data:/app/data
      - ml_models:/app/models
      - ./phase8/intel-fusion/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8008:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.31
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '3.0'
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # =============================================================
  # PHASE 9 - AUTONOMOUS ENHANCEMENT
  # =============================================================

  # Autonomous Operations Coordinator
  autonomous-coordinator:
    build:
      context: ./phase9/autonomous-coordinator
      dockerfile: Dockerfile
    container_name: bev_autonomous_coordinator
    restart: always
    depends_on:
      - postgres
      - neo4j
      - kafka-1
      - redis
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/8
      AUTONOMOUS_LEVEL: 3
      DECISION_MODEL_PATH: /app/models/decision_model.pkl
      COORDINATION_RULES: /app/config/coordination_rules.json
      MAX_AUTONOMOUS_OPERATIONS: 50
      OPERATION_TIMEOUT: 3600
      SAFETY_CONSTRAINTS: /app/config/safety_constraints.json
      LOG_LEVEL: INFO
    volumes:
      - autonomous_data:/app/data
      - ml_models:/app/models
      - ./phase9/autonomous-coordinator/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8009:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.32
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 6G
          cpus: '2.5'
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # =============================================================
  # PREDICTIVE CACHE INFRASTRUCTURE
  # =============================================================

  # ML-Driven Predictive Cache System
  predictive-cache:
    build:
      context: ./docker/predictive-cache
      dockerfile: Dockerfile
    container_name: bev_predictive_cache
    restart: always
    depends_on:
      - postgres
      - redis
      - redis-node-1
      - redis-node-2
      - redis-node-3
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_PASSWORD: ${REDIS_PASSWORD}

      # Cache configuration
      CACHE_HOT_TIER_SIZE_GB: 4.0
      CACHE_WARM_TIER_SIZE_GB: 8.0
      CACHE_DEFAULT_TTL: 3600
      CACHE_EVICTION_POLICY: ml_adaptive
      CACHE_PREFETCH_THRESHOLD: 0.7

      # ML configuration
      ML_MIN_TRAINING_SAMPLES: 1000
      ML_RETRAIN_INTERVAL_HOURS: 6
      ML_MODEL_ACCURACY_THRESHOLD: 0.8
      ML_PREDICTION_CONFIDENCE_THRESHOLD: 0.7

      # Optimization settings
      OPTIMIZATION_INTERVAL_SECONDS: 300
      OPTIMIZATION_TARGET_HIT_RATE: 0.85
      OPTIMIZATION_MAX_MEMORY_UTIL: 0.9

      # Warming configuration
      WARMING_MAX_CONCURRENT_TASKS: 10
      WARMING_INTERVAL_SECONDS: 300
      WARMING_POPULARITY_THRESHOLD: 0.1
      WARMING_MAX_BANDWIDTH_MBPS: 100

      # Service configuration
      SERVICE_HOST: 0.0.0.0
      SERVICE_PORT: 8044
      SERVICE_WORKERS: 4

      # Monitoring
      MONITORING_METRICS_INTERVAL: 60
      MONITORING_LOG_LEVEL: INFO
      MONITORING_PROMETHEUS_PORT: 9044
      MONITORING_DETAILED_LOGGING: true

      # Feature flags
      FEATURE_ML_PREDICTION_V2: false
      FEATURE_ADAPTIVE_WARMING: true
      FEATURE_COLLABORATIVE_FILTERING: false
      FEATURE_REAL_TIME_OPTIMIZATION: true
      FEATURE_ADVANCED_ANALYTICS: true

      # Security
      SECURITY_RATE_LIMITING: true
      SECURITY_REQUESTS_PER_MINUTE: 1000
      SECURITY_ENCRYPTION_IN_TRANSIT: true

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/src/infrastructure:ro
      - ./config/predictive_cache.yml:/app/config/predictive_cache.yml:ro

      # Data persistence
      - predictive_cache_data:/app/data
      - predictive_cache_models:/app/models
      - predictive_cache_cache:/app/cache

      # Logging
      - logs:/app/logs

    ports:
      - "8044:8044"  # HTTP API and cache operations
      - "9044:9044"  # Prometheus metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.44

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '4.0'
        reservations:
          memory: 8G
          cpus: '2.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8044/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9044"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=high"
      - "bev.cache-tier=predictive"
      - "bev.ml-enabled=true"
      - "bev.auto-recovery=enabled"

  # Adaptive Learning System
  adaptive-learning:
    build:
      context: ./phase9/adaptive-learning
      dockerfile: Dockerfile
    container_name: bev_adaptive_learning
    restart: always
    depends_on:
      - postgres
      - elasticsearch
      - kafka-1
      - redis
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      ELASTICSEARCH_URL: http://elasticsearch:9200
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/9
      LEARNING_RATE: 0.001
      MODEL_UPDATE_INTERVAL: 3600
      LEARNING_ALGORITHMS: reinforcement,supervised,unsupervised
      TRAINING_DATA_RETENTION: 30
      MODEL_VERSIONING: true
      AUTO_HYPERPARAMETER_TUNING: true
      PERFORMANCE_THRESHOLD: 0.85
      LOG_LEVEL: INFO
    volumes:
      - adaptive_learning_data:/app/data
      - ml_models:/app/models
      - ./phase9/adaptive-learning/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8010:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.33
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # Dynamic Resource Manager
  resource-manager:
    build:
      context: ./phase9/resource-manager
      dockerfile: Dockerfile
    container_name: bev_resource_manager
    restart: always
    depends_on:
      - postgres
      - influxdb
      - kafka-1
      - redis
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      INFLUXDB_URL: http://influxdb:8086
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_ORG: bev-osint
      INFLUXDB_BUCKET: resources
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/10
      RESOURCE_OPTIMIZATION_INTERVAL: 300
      CPU_THRESHOLD: 0.8
      MEMORY_THRESHOLD: 0.85
      DISK_THRESHOLD: 0.9
      SCALING_POLICY: /app/config/scaling_policy.json
      COST_OPTIMIZATION: true
      LOG_LEVEL: INFO
    volumes:
      - resource_manager_data:/app/data
      - ./phase9/resource-manager/config:/app/config:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - logs:/app/logs
    ports:
      - "8011:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.34
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # Knowledge Evolution System
  knowledge-evolution:
    build:
      context: ./phase9/knowledge-evolution
      dockerfile: Dockerfile
    container_name: bev_knowledge_evolution
    restart: always
    depends_on:
      - postgres
      - neo4j
      - elasticsearch
      - kafka-1
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      ELASTICSEARCH_URL: http://elasticsearch:9200
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      KNOWLEDGE_GRAPH_MODEL: /app/models/knowledge_graph.pkl
      EVOLUTION_ALGORITHMS: genetic,neural,gradient
      KNOWLEDGE_PRUNING_THRESHOLD: 0.3
      CONCEPT_DRIFT_DETECTION: true
      ONTOLOGY_UPDATE_INTERVAL: 86400
      SEMANTIC_SIMILARITY_THRESHOLD: 0.7
      LOG_LEVEL: INFO
    volumes:
      - knowledge_evolution_data:/app/data
      - ml_models:/app/models
      - ./phase9/knowledge-evolution/config:/app/config:ro
      - logs:/app/logs
    ports:
      - "8012:8000"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.35
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 12G
          cpus: '4.0'
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # Qdrant Vector Database - Primary
  qdrant-primary:
    image: qdrant/qdrant:v1.8.1
    container_name: bev_qdrant_primary
    restart: always
    environment:
      QDRANT__SERVICE__HOST: 0.0.0.0
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__CLUSTER__ENABLED: true
      QDRANT__CLUSTER__NODE_ID: 1
      QDRANT__CLUSTER__P2P__PORT: 6335
      QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS: 4
      QDRANT__STORAGE__QUANTIZATION__ALWAYS_RAM: true
      QDRANT__SERVICE__ENABLE_CORS: true
      QDRANT__LOG_LEVEL: INFO
    volumes:
      - qdrant_data:/qdrant/storage
      - qdrant_snapshots:/qdrant/snapshots
      - logs:/var/log/qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
      - "6335:6335"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.36
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Qdrant Vector Database - Replica
  qdrant-replica:
    image: qdrant/qdrant:v1.8.1
    container_name: bev_qdrant_replica
    restart: always
    environment:
      QDRANT__SERVICE__HOST: 0.0.0.0
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__CLUSTER__ENABLED: true
      QDRANT__CLUSTER__NODE_ID: 2
      QDRANT__CLUSTER__P2P__PORT: 6335
      QDRANT__CLUSTER__BOOTSTRAP: qdrant-primary:6335
      QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS: 4
      QDRANT__STORAGE__QUANTIZATION__ALWAYS_RAM: true
      QDRANT__SERVICE__ENABLE_CORS: true
      QDRANT__LOG_LEVEL: INFO
    volumes:
      - qdrant_data:/qdrant/storage
      - qdrant_snapshots:/qdrant/snapshots
      - logs:/var/log/qdrant
    ports:
      - "6336:6333"
      - "6337:6334"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.37
    depends_on:
      - qdrant-primary
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Weaviate Vector Database
  weaviate:
    image: semitechnologies/weaviate:1.23.9
    container_name: bev_weaviate
    restart: always
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'false'
      AUTHENTICATION_APIKEY_ENABLED: 'true'
      AUTHENTICATION_APIKEY_ALLOWED_KEYS: '${WEAVIATE_API_KEY}'
      AUTHENTICATION_APIKEY_USERS: 'bev-osint@admin'
      AUTHORIZATION_ADMINLIST_ENABLED: 'true'
      AUTHORIZATION_ADMINLIST_USERS: 'bev-osint@admin'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
      ENABLE_MODULES: 'text2vec-transformers,backup-filesystem,offload-s3'
      BACKUP_FILESYSTEM_PATH: '/var/lib/weaviate/backups'
      CLUSTER_HOSTNAME: 'weaviate'
      CLUSTER_GOSSIP_BIND_PORT: '7100'
      CLUSTER_DATA_BIND_PORT: '7101'
      LOG_LEVEL: 'info'
      PROMETHEUS_MONITORING_ENABLED: 'true'
      AUTOSCHEMA_ENABLED: 'false'
      TRACK_VECTOR_DIMENSIONS: 'true'
    volumes:
      - weaviate_data:/var/lib/weaviate
      - weaviate_backups:/var/lib/weaviate/backups
      - logs:/var/log/weaviate
    ports:
      - "8080:8080"
      - "7100:7100"
      - "7101:7101"
    networks:
      bev_osint:
        ipv4_address: 172.30.0.38
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 12G
          cpus: '6.0'
        reservations:
          memory: 8G
          cpus: '4.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/.well-known/ready"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Weaviate Text2Vec Transformers Module
  t2v-transformers:
    image: semitechnologies/transformers-inference:sentence-transformers-all-MiniLM-L6-v2
    container_name: bev_weaviate_transformers
    restart: always
    environment:
      ENABLE_CUDA: '0'
      NVIDIA_VISIBLE_DEVICES: 'all'
    networks:
      bev_osint:
        ipv4_address: 172.30.0.39
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/.well-known/ready"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================
  # PROXY MANAGEMENT INFRASTRUCTURE
  # =============================================================

  # Comprehensive Proxy Pool Manager
  proxy-manager:
    build:
      context: ./proxy-infrastructure
      dockerfile: Dockerfile
    container_name: bev_proxy_manager
    restart: always
    depends_on:
      - postgres
      - redis
      - tor
    environment:
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11
      TOR_PROXY: ${TOR_PROXY}

      # Proxy pool configuration
      MAX_POOL_SIZE: 10000
      HEALTH_CHECK_INTERVAL: 30
      ROTATION_INTERVAL: 1800

      # Geographic configuration
      GEOIP_DB_PATH: /app/data/GeoLite2-City.mmdb
      DEFAULT_REGIONS: us-east,us-west,eu-central

      # Load balancing
      DEFAULT_STRATEGY: least_connections
      ENABLE_LATENCY_OPTIMIZATION: true

      # Security and compliance
      ENABLE_PII_REDACTION: true
      COMPLIANCE_MODE: strict

      # Performance tuning
      MAX_CONCURRENT_CONNECTIONS: 1000
      CONNECTION_TIMEOUT: 30
      REQUEST_TIMEOUT: 60

      # Provider integrations
      PROXY_PROVIDERS: ${PROXY_PROVIDERS}
      PROVIDER_API_KEYS: ${PROVIDER_API_KEYS}

      # Monitoring
      METRICS_ENABLED: true
      PROMETHEUS_PORT: 9090

      LOG_LEVEL: INFO
    volumes:
      - ./src/infrastructure:/app/src
      - ./proxy-infrastructure/config:/app/config:ro
      - ./proxy-infrastructure/data:/app/data
      - logs:/app/logs
    ports:
      - "8013:8000"  # Main API
      - "9090:9090"  # Prometheus metrics
    networks:
      bev_osint:
        ipv4_address: 172.30.0.40
    logging: *default-logging
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Request Multiplexer - High-Performance Request Distribution
  request-multiplexer:
    build:
      context: ./src/pipeline
      dockerfile: Dockerfile.multiplexer
    container_name: bev_request_multiplexer
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - kafka-1
      - proxy-manager
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/12

      # Message queue connections
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-1:5672/
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092

      # Proxy pool integration
      PROXY_POOL_URL: http://proxy-manager:8000

      # Multiplexer configuration
      MAX_CONCURRENCY: 1000
      WORKER_COUNT: 50
      REQUEST_TIMEOUT: 30.0
      RETRY_ATTEMPTS: 3
      ENABLE_CACHING: true
      CACHE_TTL: 300

      # Connection pool settings
      MAX_CONNECTIONS: 500
      MAX_CONNECTIONS_PER_HOST: 50
      CONNECTION_TIMEOUT: 30.0
      IDLE_TIMEOUT: 300
      ENABLE_PROXY_ROTATION: true

      # Rate limiting configuration
      GLOBAL_LIMIT: 1000
      GLOBAL_WINDOW: 60
      PER_HOST_LIMIT: 100
      PER_HOST_WINDOW: 60
      BURST_LIMIT: 50
      BURST_WINDOW: 10

      # Queue management
      MAX_QUEUE_SIZE: 10000
      ENABLE_BACKPRESSURE: true
      BACKPRESSURE_THRESHOLD: 1000
      BACKPRESSURE_STRATEGY: drop_low_priority

      # Circuit breaker settings
      CIRCUIT_BREAKER_THRESHOLD: 5
      CIRCUIT_BREAKER_TIMEOUT: 60

      # Performance monitoring
      METRICS_ENABLED: true
      PROMETHEUS_PORT: 9092
      LOG_LEVEL: INFO

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30
      HEALTH_CHECK_TIMEOUT: 10

    volumes:
      - ./src/pipeline:/app/src
      - ./config/multiplexer:/app/config:ro
      - ./multiplexer/data:/app/data
      - logs:/app/logs

    ports:
      - "8015:8000"  # Main API
      - "9092:9092"  # Prometheus metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.42

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 6G
          cpus: '4.0'
        reservations:
          memory: 3G
          cpus: '2.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9092"
      - "prometheus.io/path=/metrics"
      - "bev.component=multiplexer"
      - "bev.criticality=high"
      - "bev.auto-recovery=enabled"

  # =============================================================
  # AUTO-RECOVERY INFRASTRUCTURE
  # =============================================================

  # Auto-Recovery System with Circuit Breaker Protection
  auto-recovery:
    build:
      context: ./docker/auto-recovery
      dockerfile: Dockerfile
    container_name: bev_auto_recovery
    restart: always
    depends_on:
      - postgres
      - redis
      - rabbitmq-1
      - elasticsearch
      - influxdb
    environment:
      # Database connections
      POSTGRES_URI: ${POSTGRES_URI}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11

      # Configuration
      CONFIG_PATH: /app/config/auto_recovery.yaml
      LOG_LEVEL: INFO
      WORKERS: 4

      # Recovery system settings
      MAX_CONCURRENT_RECOVERIES: 5
      GLOBAL_RECOVERY_TIMEOUT: 600.0
      SNAPSHOT_RETENTION_DAYS: 7
      METRICS_RETENTION_DAYS: 30

      # Circuit breaker defaults
      DEFAULT_FAILURE_THRESHOLD: 5
      DEFAULT_TIMEOUT_DURATION: 60.0
      DEFAULT_REQUEST_TIMEOUT: 30.0

      # Service discovery
      CONSUL_HOST: consul:8500
      DOCKER_SOCKET: unix://var/run/docker.sock

      # Alert configuration
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      BEV_ADMIN_EMAIL: ${BEV_ADMIN_EMAIL}
      BEV_ONCALL_EMAIL: ${BEV_ONCALL_EMAIL}
      RECOVERY_WEBHOOK_URL: ${RECOVERY_WEBHOOK_URL}

      # Health monitoring
      HEALTH_CHECK_INTERVAL: 30.0
      HEALTH_CHECK_TIMEOUT: 10.0
      STATE_PERSISTENCE_ENABLED: true

      # Resource thresholds
      CPU_HIGH_THRESHOLD: 80.0
      MEMORY_HIGH_THRESHOLD: 85.0
      DISK_HIGH_THRESHOLD: 90.0

      # Kubernetes support (if available)
      KUBERNETES_ENABLED: false
      KUBERNETES_NAMESPACE: bev-osint

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups
      - ./auto-recovery/snapshots:/app/snapshots

      # Logging
      - logs:/app/logs

      # State backup paths (for snapshot creation)
      - postgres_data:/backup/postgres:ro
      - neo4j_data:/backup/neo4j:ro
      - redis_data:/backup/redis:ro
      - elasticsearch_data:/backup/elasticsearch:ro
      - qdrant_data:/backup/qdrant:ro
      - weaviate_data:/backup/weaviate:ro

    ports:
      - "8014:8000"  # HTTP API and health checks
      - "9091:9000"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9000"
      - "prometheus.io/path=/metrics"
      - "bev.component=infrastructure"
      - "bev.criticality=critical"
      - "bev.auto-recovery=enabled"

  # =============================================================
  # CONTEXT COMPRESSION SERVICE
  # =============================================================

  # Context Compression Engine
  context-compressor:
    build:
      context: .
      dockerfile: ./src/pipeline/Dockerfile.compression
    container_name: bev_context_compressor
    restart: always

    environment:
      # Core Configuration
      COMPRESSION_STRATEGY: balanced
      TARGET_COMPRESSION_RATIO: 0.4
      MAX_INFORMATION_LOSS: 0.05

      # Database Connections
      REDIS_HOST: redis-standalone
      REDIS_PORT: 6379
      MONGODB_URL: mongodb://postgres:5432/compression_metadata
      QDRANT_HOST: qdrant-primary
      QDRANT_PORT: 6333
      WEAVIATE_HOST: weaviate-primary
      WEAVIATE_PORT: 8080

      # Vector Database Integration
      VECTOR_DB_INTEGRATION: "true"
      ENABLE_CACHING: "true"
      QUALITY_VALIDATION: "true"

      # Semantic Deduplication
      SEMANTIC_SIMILARITY_THRESHOLD: 0.85
      SEMANTIC_CLUSTERING_EPS: 0.3
      SEMANTIC_MODEL: all-MiniLM-L6-v2

      # Entropy Compression
      ENTROPY_BLOCK_SIZE: 1024
      ENTROPY_TARGET_RATIO: 0.5
      COMPRESSION_METHODS: gzip,lzma,bz2,zlib

      # Quality Thresholds
      MIN_SIMILARITY_SCORE: 0.95
      MIN_COHERENCE_SCORE: 0.8
      MIN_BLEU_SCORE: 0.8
      MIN_ROUGE_SCORE: 0.8
      MAX_READABILITY_DEGRADATION: 0.2
      MIN_RECONSTRUCTION_ACCURACY: 0.95

      # Performance Settings
      BATCH_SIZE: 32
      MAX_CONTENT_LENGTH: 10000
      ENABLE_DEEP_ANALYSIS: "true"
      ENABLE_LINGUISTIC_ANALYSIS: "true"
      ENABLE_SEMANTIC_ANALYSIS: "true"
      ENABLE_STRUCTURAL_ANALYSIS: "true"

      # API Configuration
      API_HOST: 0.0.0.0
      API_PORT: 8000
      API_WORKERS: 4
      DEBUG: "false"
      LOG_LEVEL: INFO

    volumes:
      # Application code
      - ./src/pipeline:/app/src/pipeline:ro
      - ./src/infrastructure:/app/src/infrastructure:ro

      # Configuration
      - ./config/context_compression.yaml:/app/config/compression.yaml:ro

      # Data persistence
      - context_compression_data:/app/data
      - compression_cache:/app/cache
      - ml_models:/app/models

      # Logs
      - logs:/app/logs

    ports:
      - "8015:8000"  # HTTP API
      - "9092:9090"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.43

    depends_on:
      - redis-standalone
      - postgres
      - qdrant-primary
      - weaviate-primary

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '3.0'
        reservations:
          memory: 2G
          cpus: '1.5'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9090"
      - "prometheus.io/path=/metrics"
      - "bev.component=compression"
      - "bev.criticality=high"
      - "bev.auto-recovery=enabled"

  # Context Compression Auto-Recovery
  context-compressor-recovery:
    build:
      context: .
      dockerfile: ./src/infrastructure/auto-recovery/Dockerfile
    container_name: bev_context_compressor_recovery
    restart: always

    environment:
      TARGET_SERVICE: context-compressor
      SERVICE_NAME: "Context Compression Engine"
      HEALTH_CHECK_URL: http://context-compressor:8000/health
      RECOVERY_STRATEGY: restart
      MAX_RESTART_ATTEMPTS: 5
      MONITORING_INTERVAL: 30
      ESCALATION_THRESHOLD: 3
      NOTIFICATION_WEBHOOK: ${DISCORD_WEBHOOK_URL}
      LOG_LEVEL: INFO

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups

      # Logs
      - logs:/app/logs

    networks:
      bev_osint:
        ipv4_address: 172.30.0.44

    depends_on:
      - context-compressor

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 30s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "bev.component=auto-recovery"
      - "bev.target-service=context-compressor"
      - "bev.criticality=medium"


  # Extended Reasoning Pipeline
  extended-reasoning:
    build:
      context: .
      dockerfile: ./src/agents/Dockerfile.extended_reasoning
    container_name: bev_extended_reasoning
    restart: always

    environment:
      # Core configuration
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      REDIS_URL: redis://172.30.0.5:6379/3

      # Service configuration
      COMPRESSION_ENDPOINT: http://172.30.0.43:8000
      VECTOR_DB_ENDPOINT: http://172.30.0.44:8000

      # Processing configuration
      MAX_TOKENS: 100000
      CHUNK_SIZE: 8000
      OVERLAP_RATIO: 0.1
      MIN_CONFIDENCE: 0.6
      MAX_PROCESSING_TIME: 600

      # Performance configuration
      WORKERS: 4
      MEMORY_LIMIT: 4G
      CPU_LIMIT: 3.0
      PARALLEL_WORKERS: 4

      # Monitoring
      LOG_LEVEL: INFO
      METRICS_ENABLED: true
      HEALTH_CHECK_ENABLED: true

    volumes:
      # Application code and configuration
      - ./src/agents:/app/src/agents:ro
      - ./config/extended_reasoning.yaml:/app/config/extended_reasoning.yaml:ro

      # Data persistence and processing
      - extended_reasoning_data:/app/data
      - extended_reasoning_cache:/app/cache
      - extended_reasoning_models:/app/models

      # Logs
      - logs:/app/logs

    ports:
      - "8016:8000"  # HTTP API
      - "9093:9090"  # Metrics and monitoring

    networks:
      bev_osint:
        ipv4_address: 172.30.0.46

    depends_on:
      - postgres
      - redis-standalone
      - context-compressor
      - qdrant-primary
      - weaviate

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '3.0'
        reservations:
          memory: 2G
          cpus: '1.5'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=9090"
      - "prometheus.io/path=/metrics"
      - "bev.component=extended-reasoning"
      - "bev.criticality=high"
      - "bev.auto-recovery=enabled"

  # Extended Reasoning Auto-Recovery
  extended-reasoning-recovery:
    build:
      context: .
      dockerfile: ./src/infrastructure/auto-recovery/Dockerfile
    container_name: bev_extended_reasoning_recovery
    restart: always

    environment:
      TARGET_SERVICE: extended-reasoning
      SERVICE_NAME: "Extended Reasoning Pipeline"
      HEALTH_CHECK_URL: http://extended-reasoning:8000/health
      RECOVERY_STRATEGY: restart
      MAX_RESTART_ATTEMPTS: 5
      MONITORING_INTERVAL: 30
      ESCALATION_THRESHOLD: 3
      NOTIFICATION_WEBHOOK: ${DISCORD_WEBHOOK_URL}
      LOG_LEVEL: INFO

    volumes:
      # Application code and configuration
      - ./src/infrastructure:/app/infrastructure:ro
      - ./config/auto_recovery.yaml:/app/config/auto_recovery.yaml:ro

      # Docker socket for container management
      - /var/run/docker.sock:/var/run/docker.sock:ro

      # Data persistence
      - ./auto-recovery/data:/app/data
      - ./auto-recovery/backups:/app/backups

      # Logs
      - logs:/app/logs

    networks:
      bev_osint:
        ipv4_address: 172.30.0.47

    depends_on:
      - extended-reasoning

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 30s

    # Security context
    user: "1000:1000"

    # Resource monitoring
    labels:
      - "bev.component=auto-recovery"
      - "bev.target-service=extended-reasoning"
      - "bev.criticality=medium"

  # Chaos Engineering System
  chaos-engineer:
    build:
      context: .
      dockerfile: ./docker/chaos-engineering/Dockerfile
    container_name: bev_chaos_engineer
    restart: unless-stopped

    environment:
      # Core configuration
      PYTHONPATH: /app
      PYTHONUNBUFFERED: 1
      LOG_LEVEL: INFO

      # Service integration URLs
      AUTO_RECOVERY_URL: http://172.30.0.41:8080
      HEALTH_MONITOR_URL: http://172.30.0.38:8080

      # Redis configuration
      REDIS_URL: redis://redis:6379/12

      # Safety configuration
      PRODUCTION_MODE: false
      MAX_CONCURRENT_EXPERIMENTS: 3
      EMERGENCY_STOP_THRESHOLD: 0.8

      # Docker integration
      DOCKER_HOST: unix:///var/run/docker.sock

    volumes:
      # Application code and configuration
      - ./src/testing:/app/src/testing:ro
      - ./docker/chaos-engineering/config:/app/config:ro

      # Docker socket for container management (requires privileged access)
      - /var/run/docker.sock:/var/run/docker.sock

      # Data persistence
      - ./chaos-engineering/data:/app/data
      - ./chaos-engineering/experiments:/app/experiments
      - ./chaos-engineering/scenarios:/app/scenarios

      # Logs
      - logs:/app/logs

    ports:
      - "8045:8080"  # Chaos engineering API

    networks:
      bev_osint:
        ipv4_address: 172.30.0.45

    depends_on:
      - redis-node-1
      - postgres

    logging: *default-logging

    # Privileged access for network and system operations
    privileged: true

    # Additional capabilities for fault injection
    cap_add:
      - NET_ADMIN
      - SYS_ADMIN
      - SYS_PTRACE

    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    # Security context
    user: "0:0"  # Root required for system-level fault injection

    # Resource monitoring
    labels:
      - "bev.component=chaos-engineering"
      - "bev.service=chaos-engineer"
      - "bev.criticality=low"
      - "bev.category=testing"
      - "bev.auto-recovery=disabled"

  # ===================================================================
  # EDGE COMPUTING NETWORK SERVICES
  # ===================================================================

  # US East Edge Node
  edge-node-us-east:
    build:
      context: .
      dockerfile: docker/edge_computing/Dockerfile.edge_node
      args:
        - REGION=us-east
        - PYTHON_VERSION=3.11

    image: bev-osint/edge-node:us-east-latest

    container_name: bev-edge-us-east

    restart: unless-stopped

    environment:
      - NODE_ID=edge-us-east-001
      - REGION=us-east
      - IP_ADDRESS=172.30.0.47
      - SERVICE_PORT=8000
      - MODEL_PORT=8001
      - ADMIN_PORT=8002
      - METRICS_PORT=9090
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - CACHE_ENDPOINT=http://172.30.0.44:6379
      - MULTIPLEX_ENDPOINT=http://172.30.0.42:8080
      - MODEL_CACHE_SIZE=3
      - MAX_CONCURRENT_REQUESTS=100
      - MEMORY_LIMIT_GB=16
      - GPU_MEMORY_LIMIT_GB=8
      - HEALTH_CHECK_INTERVAL=30
      - MODEL_SYNC_INTERVAL=300
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - edge_models_us_east:/opt/models
      - edge_logs_data:/var/log/bev_edge
      - ./src/edge:/app/src/edge:ro
      - ./config:/app/config:ro

    ports:
      - "8047:8000"  # Edge API
      - "8147:8001"  # Model API
      - "8247:8002"  # Admin API
      - "9047:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.47

    depends_on:
      - postgres
      - redis-node-1

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8.0'
        reservations:
          memory: 8G
          cpus: '4.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=edge-computing"
      - "bev.service=edge-node"
      - "bev.region=us-east"
      - "bev.criticality=high"
      - "bev.category=inference"
      - "bev.auto-recovery=enabled"

  # US West Edge Node
  edge-node-us-west:
    build:
      context: .
      dockerfile: docker/edge_computing/Dockerfile.edge_node
      args:
        - REGION=us-west
        - PYTHON_VERSION=3.11

    image: bev-osint/edge-node:us-west-latest

    container_name: bev-edge-us-west

    restart: unless-stopped

    environment:
      - NODE_ID=edge-us-west-001
      - REGION=us-west
      - IP_ADDRESS=172.30.0.48
      - SERVICE_PORT=8000
      - MODEL_PORT=8001
      - ADMIN_PORT=8002
      - METRICS_PORT=9090
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - CACHE_ENDPOINT=http://172.30.0.44:6379
      - MULTIPLEX_ENDPOINT=http://172.30.0.42:8080
      - MODEL_CACHE_SIZE=3
      - MAX_CONCURRENT_REQUESTS=100
      - MEMORY_LIMIT_GB=16
      - GPU_MEMORY_LIMIT_GB=8
      - HEALTH_CHECK_INTERVAL=30
      - MODEL_SYNC_INTERVAL=300
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - edge_models_us_west:/opt/models
      - edge_logs_data:/var/log/bev_edge
      - ./src/edge:/app/src/edge:ro
      - ./config:/app/config:ro

    ports:
      - "8048:8000"  # Edge API
      - "8148:8001"  # Model API
      - "8248:8002"  # Admin API
      - "9048:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.48

    depends_on:
      - postgres
      - redis-node-1

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8.0'
        reservations:
          memory: 8G
          cpus: '4.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=edge-computing"
      - "bev.service=edge-node"
      - "bev.region=us-west"
      - "bev.criticality=high"
      - "bev.category=inference"
      - "bev.auto-recovery=enabled"

  # EU Central Edge Node
  edge-node-eu-central:
    build:
      context: .
      dockerfile: docker/edge_computing/Dockerfile.edge_node
      args:
        - REGION=eu-central
        - PYTHON_VERSION=3.11

    image: bev-osint/edge-node:eu-central-latest

    container_name: bev-edge-eu-central

    restart: unless-stopped

    environment:
      - NODE_ID=edge-eu-central-001
      - REGION=eu-central
      - IP_ADDRESS=172.30.0.49
      - SERVICE_PORT=8000
      - MODEL_PORT=8001
      - ADMIN_PORT=8002
      - METRICS_PORT=9090
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - CACHE_ENDPOINT=http://172.30.0.44:6379
      - MULTIPLEX_ENDPOINT=http://172.30.0.42:8080
      - MODEL_CACHE_SIZE=2
      - MAX_CONCURRENT_REQUESTS=80
      - MEMORY_LIMIT_GB=12
      - GPU_MEMORY_LIMIT_GB=6
      - HEALTH_CHECK_INTERVAL=30
      - MODEL_SYNC_INTERVAL=300
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
      - TZ=Europe/Berlin
      - GDPR_ENABLED=true
      - DATA_RETENTION_DAYS=30

    volumes:
      - edge_models_eu_central:/opt/models
      - edge_logs_data:/var/log/bev_edge
      - ./src/edge:/app/src/edge:ro
      - ./config:/app/config:ro

    ports:
      - "8049:8000"  # Edge API
      - "8149:8001"  # Model API
      - "8249:8002"  # Admin API
      - "9049:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.49

    depends_on:
      - postgres
      - redis-node-1

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 12G
          cpus: '6.0'
        reservations:
          memory: 6G
          cpus: '3.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=edge-computing"
      - "bev.service=edge-node"
      - "bev.region=eu-central"
      - "bev.criticality=high"
      - "bev.category=inference"
      - "bev.compliance=gdpr"
      - "bev.auto-recovery=enabled"

  # Asia Pacific Edge Node
  edge-node-asia-pacific:
    build:
      context: .
      dockerfile: docker/edge_computing/Dockerfile.edge_node
      args:
        - REGION=asia-pacific
        - PYTHON_VERSION=3.11

    image: bev-osint/edge-node:asia-pacific-latest

    container_name: bev-edge-asia-pacific

    restart: unless-stopped

    environment:
      - NODE_ID=edge-asia-pacific-001
      - REGION=asia-pacific
      - IP_ADDRESS=172.30.0.50
      - SERVICE_PORT=8000
      - MODEL_PORT=8001
      - ADMIN_PORT=8002
      - METRICS_PORT=9090
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - CACHE_ENDPOINT=http://172.30.0.44:6379
      - MULTIPLEX_ENDPOINT=http://172.30.0.42:8080
      - MODEL_CACHE_SIZE=2
      - MAX_CONCURRENT_REQUESTS=60
      - MEMORY_LIMIT_GB=10
      - GPU_MEMORY_LIMIT_GB=4
      - HEALTH_CHECK_INTERVAL=30
      - MODEL_SYNC_INTERVAL=300
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
      - TZ=Asia/Singapore
      - LATENCY_OPTIMIZATION=true
      - BANDWIDTH_ADAPTIVE=true

    volumes:
      - edge_models_asia_pacific:/opt/models
      - edge_logs_data:/var/log/bev_edge
      - ./src/edge:/app/src/edge:ro
      - ./config:/app/config:ro

    ports:
      - "8050:8000"  # Edge API
      - "8150:8001"  # Model API
      - "8250:8002"  # Admin API
      - "9050:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.50

    depends_on:
      - postgres
      - redis-node-1

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 10G
          cpus: '4.0'
        reservations:
          memory: 5G
          cpus: '2.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=edge-computing"
      - "bev.service=edge-node"
      - "bev.region=asia-pacific"
      - "bev.criticality=high"
      - "bev.category=inference"
      - "bev.auto-recovery=enabled"

  # Edge Management Service (Central Orchestrator)
  edge-management:
    build:
      context: .
      dockerfile: docker/edge_computing/Dockerfile.edge_management
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/edge-management:latest

    container_name: bev-edge-management

    restart: unless-stopped

    environment:
      - SERVICE_PORT=8080
      - ADMIN_PORT=8081
      - METRICS_PORT=9090
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - ENABLE_AUTO_SCALING=true
      - ENABLE_MODEL_SYNC=true
      - ENABLE_GEO_ROUTING=true
      - MAX_CONCURRENT_REQUESTS=1000
      - HEALTH_CHECK_INTERVAL=30
      - PERFORMANCE_OPTIMIZATION_INTERVAL=300
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - edge_logs_data:/var/log/bev_edge
      - ./src/edge:/app/src/edge:ro
      - ./config:/app/config:ro

    ports:
      - "8046:8080"  # Management API
      - "8146:8081"  # Admin API
      - "9046:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.46

    depends_on:
      - postgres
      - redis-node-1
      - edge-node-us-east
      - edge-node-us-west
      - edge-node-eu-central
      - edge-node-asia-pacific

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    labels:
      - "bev.component=edge-computing"
      - "bev.service=edge-management"
      - "bev.criticality=critical"
      - "bev.category=orchestration"
      - "bev.auto-recovery=enabled"

  # Model Synchronizer Service
  model-synchronizer:
    build:
      context: .
      dockerfile: docker/edge_computing/Dockerfile.model_sync
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/model-synchronizer:latest

    container_name: bev-model-synchronizer

    restart: unless-stopped

    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - BASE_MODEL_PATH=/opt/models
      - TEMP_DOWNLOAD_PATH=/tmp/model_downloads
      - MAX_CONCURRENT_DOWNLOADS=3
      - CHUNK_SIZE=1048576
      - HEALTH_CHECK_INTERVAL=300
      - SYNC_SCHEDULER_INTERVAL=3600
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
      # Hugging Face Hub configuration
      - HF_HUB_CACHE=/opt/models/.cache
      - HF_HUB_ENABLE_HF_TRANSFER=1

    volumes:
      - edge_models_us_east:/opt/models/us-east
      - edge_models_us_west:/opt/models/us-west
      - edge_models_eu_central:/opt/models/eu-central
      - edge_models_asia_pacific:/opt/models/asia-pacific
      - edge_cache_data:/opt/models/.cache
      - edge_logs_data:/var/log/bev_edge
      - ./src/edge:/app/src/edge:ro
      - ./config:/app/config:ro

    ports:
      - "8051:8080"  # Sync API
      - "9051:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.51

    depends_on:
      - postgres
      - redis-node-1

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=edge-computing"
      - "bev.service=model-synchronizer"
      - "bev.criticality=high"
      - "bev.category=infrastructure"
      - "bev.auto-recovery=enabled"

  # Geographic Router Service
  geo-router:
    build:
      context: .
      dockerfile: docker/edge_computing/Dockerfile.geo_router
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/geo-router:latest

    container_name: bev-geo-router

    restart: unless-stopped

    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - DEFAULT_STRATEGY=hybrid
      - MAX_ROUTING_TIME_MS=100
      - LATENCY_WEIGHT=0.4
      - LOAD_WEIGHT=0.3
      - GEOGRAPHIC_WEIGHT=0.2
      - COST_WEIGHT=0.1
      - HEALTH_CHECK_INTERVAL=30
      - LATENCY_MEASUREMENT_INTERVAL=60
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - edge_logs_data:/var/log/bev_edge
      - ./src/edge:/app/src/edge:ro
      - ./config:/app/config:ro
      - ./data/geoip:/opt/geoip:ro  # GeoIP database

    ports:
      - "8052:8080"  # Router API
      - "9052:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.52

    depends_on:
      - postgres
      - redis-node-1
      - edge-node-us-east
      - edge-node-us-west
      - edge-node-eu-central
      - edge-node-asia-pacific

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    labels:
      - "bev.component=edge-computing"
      - "bev.service=geo-router"
      - "bev.criticality=high"
      - "bev.category=routing"
      - "bev.auto-recovery=enabled"

  # =============================================================
  # INTELLIGENCE ENHANCEMENT LAYER - Predictive Cache
  # =============================================================

  # Predictive Cache Service
  predictive-cache:
    build:
      context: .
      dockerfile: docker/predictive_cache/Dockerfile.predictive_cache
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/predictive-cache:latest
    container_name: bev_predictive_cache
    restart: unless-stopped

    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - REDIS_DB=11
      - QDRANT_HOST=qdrant-primary
      - QDRANT_PORT=6333
      - WEAVIATE_HOST=weaviate
      - WEAVIATE_PORT=8080
      - CONTEXT_COMPRESSOR_URL=http://context-compressor:8080
      - CACHE_TTL=3600
      - PREDICTION_WINDOW=900
      - MAX_CACHE_SIZE_GB=10
      - LEARNING_RATE=0.001
      - BATCH_SIZE=64
      - MODEL_UPDATE_INTERVAL=3600
      - FEATURE_WINDOW_SIZE=100
      - CONFIDENCE_THRESHOLD=0.7
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - predictive_cache_data:/var/lib/predictive_cache
      - predictive_cache_models:/var/lib/predictive_models
      - predictive_cache_cache:/var/cache/predictive_cache
      - ./src/predictive_cache:/app/src/predictive_cache:ro
      - ./config:/app/config:ro

    ports:
      - "8044:8080"  # Cache API
      - "9044:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.44

    depends_on:
      - context-compressor
      - qdrant-primary
      - weaviate

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=predictive-cache"
      - "bev.service=predictive-cache"
      - "bev.criticality=high"
      - "bev.category=intelligence"
      - "bev.auto-recovery=enabled"

  # Extended Reasoning Recovery Service
  extended-reasoning-recovery:
    build:
      context: .
      dockerfile: docker/auto_recovery/Dockerfile.auto_recovery
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/auto-recovery:latest
    container_name: bev_extended_reasoning_recovery
    restart: unless-stopped

    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - REDIS_DB=12
      - HEALTH_MONITOR_URL=http://health-monitor:8080
      - TARGET_SERVICE=extended-reasoning
      - RECOVERY_CHECK_INTERVAL=60
      - MAX_RECOVERY_ATTEMPTS=3
      - RECOVERY_TIMEOUT=300
      - ESCALATION_THRESHOLD=5
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - recovery_logs_data:/var/lib/recovery_logs
      - recovery_state_data:/var/lib/recovery_state
      - ./src/auto_recovery:/app/src/auto_recovery:ro
      - ./config:/app/config:ro
      - /var/run/docker.sock:/var/run/docker.sock

    ports:
      - "8047:8080"  # Recovery API for Extended Reasoning
      - "9047:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.53

    depends_on:
      - extended-reasoning
      - health-monitor

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=auto-recovery"
      - "bev.service=extended-reasoning-recovery"
      - "bev.criticality=high"
      - "bev.category=automation"

  # Context Compressor Recovery Service
  context-compressor-recovery:
    build:
      context: .
      dockerfile: docker/auto_recovery/Dockerfile.auto_recovery
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/auto-recovery:latest
    container_name: bev_context_compressor_recovery
    restart: unless-stopped

    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - REDIS_DB=13
      - HEALTH_MONITOR_URL=http://health-monitor:8080
      - TARGET_SERVICE=context-compressor
      - RECOVERY_CHECK_INTERVAL=60
      - MAX_RECOVERY_ATTEMPTS=3
      - RECOVERY_TIMEOUT=300
      - ESCALATION_THRESHOLD=5
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - recovery_logs_data:/var/lib/recovery_logs
      - recovery_state_data:/var/lib/recovery_state
      - ./src/auto_recovery:/app/src/auto_recovery:ro
      - ./config:/app/config:ro
      - /var/run/docker.sock:/var/run/docker.sock

    ports:
      - "8054:8080"  # Recovery API for Context Compressor
      - "9054:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.54

    depends_on:
      - context-compressor
      - health-monitor

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=auto-recovery"
      - "bev.service=context-compressor-recovery"
      - "bev.criticality=high"
      - "bev.category=automation"
