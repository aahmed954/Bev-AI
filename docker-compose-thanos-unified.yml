version: '3.9'
x-logging: &id001
  driver: json-file
  options:
    max-size: 10m
    max-file: '3'
networks:
  bev_osint:
    driver: bridge
    ipam:
      config:
      - subnet: 172.21.0.0/16
volumes:
  postgres_data: null
  neo4j_data: null
  redis_data: null
  elasticsearch_data: null
  influxdb_data: null
  kafka_data: null
  zookeeper_data: null
  rabbitmq_data: null
  tor_data: null
  intelowl_postgres_data: null
  intelowl_static_data: null
  prometheus_data: null
  grafana_data: null
  airflow_logs: null
  airflow_dags: null
  airflow_plugins: null
  airflow_config: null
  ocr_data: null
  document_analyzer_data: null
  swarm_data: null
  memory_data: null
  code_data: null
  tool_data: null
  vault_data: null
  guardian_data: null
  tor_nodes_data: null
  ids_data: null
  security_logs: null
  autonomous_data: null
  live2d_data: null
  avatar_assets: null
  logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /home/starlord/Projects/Bev/logs
services:
  postgres:
    image: pgvector/pgvector:pg16
    platform: linux/amd64
    container_name: bev_postgres
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_MULTIPLE_DATABASES: osint,intelowl,breach_data,crypto_analysis
      POSTGRES_HOST_AUTH_METHOD: md5
      SHARED_PRELOAD_LIBRARIES: pg_stat_statements,pgvector
      MAX_CONNECTIONS: 500
      SHARED_BUFFERS: 2GB
      EFFECTIVE_CACHE_SIZE: 6GB
      MAINTENANCE_WORK_MEM: 512MB
      WORK_MEM: 32MB
    volumes:
    - postgres_data:/var/lib/postgresql/data
    - ./init_scripts/postgres_init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    - logs:/var/log/postgresql
    ports:
    - 5432:5432
    networks:
      bev_osint:
        ipv4_address: 172.21.0.2
    logging: *id001
    healthcheck:
      test:
      - CMD-SHELL
      - pg_isready -U ${POSTGRES_USER}
      interval: 10s
      timeout: 5s
      retries: 5
  neo4j:
    image: neo4j:5.14-enterprise
    platform: linux/amd64
    container_name: bev_neo4j
    restart: always
    environment:
      NEO4J_AUTH: ${NEO4J_USER}/${NEO4J_PASSWORD}
      NEO4J_ACCEPT_LICENSE_AGREEMENT: 'yes'
      NEO4J_dbms_security_procedures_unrestricted: apoc.*,gds.*
      NEO4J_dbms_security_procedures_allowlist: apoc.*,gds.*
      NEO4J_apoc_export_file_enabled: 'true'
      NEO4J_apoc_import_file_enabled: 'true'
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
      NEO4J_dbms_connector_bolt_listen__address: 0.0.0.0:7687
      NEO4J_dbms_connector_http_listen__address: 0.0.0.0:7474
      NEO4J_dbms_connector_https_listen__address: 0.0.0.0:7473
    volumes:
    - neo4j_data:/data
    - ./init_scripts/neo4j_init.cypher:/import/init.cypher:ro
    - logs:/logs
    ports:
    - 7474:7474
    - 7687:7687
    - 7473:7473
    networks:
      bev_osint:
        ipv4_address: 172.21.0.3
    logging: *id001
  redis-node-1:
    image: redis:7-alpine
    platform: linux/amd64
    container_name: bev_redis_1
    restart: always
    command: 'redis-server --port 7001 --cluster-enabled yes --cluster-config-file
      nodes.conf --cluster-node-timeout 5000 --appendonly yes --requirepass ${REDIS_PASSWORD}
      --masterauth ${REDIS_PASSWORD} --maxmemory 2gb --maxmemory-policy allkeys-lru

      '
    volumes:
    - ./redis/node1:/data
    - logs:/var/log/redis
    ports:
    - 7001:7001
    - 17001:17001
    networks:
      bev_osint:
        ipv4_address: 172.21.0.4
    logging: *id001
  redis-node-2:
    image: redis:7-alpine
    platform: linux/amd64
    container_name: bev_redis_2
    restart: always
    command: 'redis-server --port 7002 --cluster-enabled yes --cluster-config-file
      nodes.conf --cluster-node-timeout 5000 --appendonly yes --requirepass ${REDIS_PASSWORD}
      --masterauth ${REDIS_PASSWORD} --maxmemory 2gb --maxmemory-policy allkeys-lru

      '
    volumes:
    - ./redis/node2:/data
    - logs:/var/log/redis
    ports:
    - 7002:7002
    - 17002:17002
    networks:
      bev_osint:
        ipv4_address: 172.21.0.5
    logging: *id001
  redis-node-3:
    image: redis:7-alpine
    platform: linux/amd64
    container_name: bev_redis_3
    restart: always
    command: 'redis-server --port 7003 --cluster-enabled yes --cluster-config-file
      nodes.conf --cluster-node-timeout 5000 --appendonly yes --requirepass ${REDIS_PASSWORD}
      --masterauth ${REDIS_PASSWORD} --maxmemory 2gb --maxmemory-policy allkeys-lru

      '
    volumes:
    - ./redis/node3:/data
    - logs:/var/log/redis
    ports:
    - 7003:7003
    - 17003:17003
    networks:
      bev_osint:
        ipv4_address: 172.21.0.6
    logging: *id001
  redis:
    image: redis:7-alpine
    platform: linux/amd64
    container_name: bev_redis_standalone
    restart: always
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 1gb --maxmemory-policy
      allkeys-lru
    volumes:
    - redis_data:/data
    ports:
    - 6379:6379
    networks:
      bev_osint:
        ipv4_address: 172.21.0.7
    logging: *id001
  rabbitmq-1:
    image: rabbitmq:3-management
    platform: linux/amd64
    container_name: bev_rabbitmq_1
    hostname: rabbitmq-1
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_ERLANG_COOKIE: BevRabbitClusterCookie2024
      RABBITMQ_NODENAME: rabbit@rabbitmq-1
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: -rabbit disk_free_limit 2147483648
    volumes:
    - ./rabbitmq/node1:/var/lib/rabbitmq
    - logs:/var/log/rabbitmq
    ports:
    - 5672:5672
    - 15672:15672
    networks:
      bev_osint:
        ipv4_address: 172.21.0.8
    logging: *id001
  rabbitmq-2:
    image: rabbitmq:3-management
    platform: linux/amd64
    container_name: bev_rabbitmq_2
    hostname: rabbitmq-2
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_ERLANG_COOKIE: BevRabbitClusterCookie2024
      RABBITMQ_NODENAME: rabbit@rabbitmq-2
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: -rabbit disk_free_limit 2147483648
    volumes:
    - ./rabbitmq/node2:/var/lib/rabbitmq
    - logs:/var/log/rabbitmq
    ports:
    - 5673:5672
    - 15673:15672
    networks:
      bev_osint:
        ipv4_address: 172.21.0.9
    logging: *id001
  rabbitmq-3:
    image: rabbitmq:3-management
    platform: linux/amd64
    container_name: bev_rabbitmq_3
    hostname: rabbitmq-3
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_ERLANG_COOKIE: BevRabbitClusterCookie2024
      RABBITMQ_NODENAME: rabbit@rabbitmq-3
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: -rabbit disk_free_limit 2147483648
    volumes:
    - ./rabbitmq/node3:/var/lib/rabbitmq
    - logs:/var/log/rabbitmq
    ports:
    - 5674:5672
    - 15674:15672
    networks:
      bev_osint:
        ipv4_address: 172.21.0.10
    logging: *id001
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    platform: linux/amd64
    container_name: bev_zookeeper
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_MAX_CLIENT_CNXNS: 100
    volumes:
    - zookeeper_data:/var/lib/zookeeper/data
    - ./zookeeper/log:/var/lib/zookeeper/log
    - logs:/var/log/zookeeper
    ports:
    - 2181:2181
    networks:
      bev_osint:
        ipv4_address: 172.21.0.11
    logging: *id001
  kafka-1:
    image: confluentinc/cp-kafka:7.5.0
    platform: linux/amd64
    container_name: bev_kafka_1
    restart: always
    depends_on:
    - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092,EXTERNAL://0.0.0.0:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
    volumes:
    - ./kafka/broker1:/var/lib/kafka/data
    - logs:/var/log/kafka
    ports:
    - 19092:19092
    networks:
      bev_osint:
        ipv4_address: 172.21.0.12
    logging: *id001
  kafka-2:
    image: confluentinc/cp-kafka:7.5.0
    platform: linux/amd64
    container_name: bev_kafka_2
    restart: always
    depends_on:
    - zookeeper
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:9092,EXTERNAL://0.0.0.0:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
    volumes:
    - ./kafka/broker2:/var/lib/kafka/data
    - logs:/var/log/kafka
    ports:
    - 29092:29092
    networks:
      bev_osint:
        ipv4_address: 172.21.0.13
    logging: *id001
  kafka-3:
    image: confluentinc/cp-kafka:7.5.0
    platform: linux/amd64
    container_name: bev_kafka_3
    restart: always
    depends_on:
    - zookeeper
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:9092,EXTERNAL://0.0.0.0:39092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_NUM_PARTITIONS: 3
    volumes:
    - ./kafka/broker3:/var/lib/kafka/data
    - logs:/var/log/kafka
    ports:
    - 39092:39092
    networks:
      bev_osint:
        ipv4_address: 172.21.0.14
    logging: *id001
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    platform: linux/amd64
    container_name: bev_elasticsearch
    restart: always
    environment:
    - discovery.type=single-node
    - xpack.security.enabled=false
    - xpack.security.enrollment.enabled=false
    - ES_JAVA_OPTS=-Xms2g -Xmx2g
    - cluster.name=bev-osint-cluster
    - bootstrap.memory_lock=true
    - indices.query.bool.max_clause_count=10000
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
    - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
    - 9200:9200
    - 9300:9300
    networks:
      bev_osint:
        ipv4_address: 172.21.0.15
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:9200
      interval: 30s
      timeout: 10s
      retries: 5
  influxdb:
    image: influxdb:2.7
    platform: linux/amd64
    container_name: bev_influxdb
    restart: always
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: bev
      DOCKER_INFLUXDB_INIT_PASSWORD: BevMetrics2024
      DOCKER_INFLUXDB_INIT_ORG: bev-osint
      DOCKER_INFLUXDB_INIT_BUCKET: metrics
      DOCKER_INFLUXDB_INIT_RETENTION: 30d
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_DATA_QUERY_LOG_ENABLED: 'false'
      INFLUXDB_HTTP_LOG_ENABLED: 'false'
    volumes:
    - influxdb_data:/var/lib/influxdb2
    - ./influxdb/config:/etc/influxdb2
    - logs:/var/log/influxdb
    ports:
    - 8086:8086
    networks:
      bev_osint:
        ipv4_address: 172.21.0.16
    logging: *id001
  tor:
    image: dperson/torproxy:latest
    platform: linux/amd64
    container_name: bev_tor
    restart: always
    environment:
      TORUSER: bev
      PASSWORD: ${TOR_CONTROL_PASSWORD}
      TOR_NewCircuitPeriod: 600
      TOR_MaxCircuitDirtiness: 600
      TOR_NumEntryGuards: 6
      TOR_ControlPort: 9051
      TOR_HashedControlPassword: 16:872860B76453A77D60CA2BB8C1A7042072093276A3D701AD684053EC4C
    volumes:
    - tor_data:/var/lib/tor
    - ./tor/torrc:/etc/tor/torrc:ro
    - logs:/var/log/tor
    ports:
    - 9050:9050
    - 9051:9051
    - 8118:8118
    networks:
      bev_osint:
        ipv4_address: 172.21.0.17
    logging: *id001
  intelowl-postgres:
    image: postgres:16-alpine
    platform: linux/amd64
    container_name: bev_intelowl_postgres
    restart: always
    environment:
      POSTGRES_DB: ${INTELOWL_POSTGRES_DB}
      POSTGRES_USER: ${INTELOWL_POSTGRES_USER}
      POSTGRES_PASSWORD: ${INTELOWL_POSTGRES_PASSWORD}
    volumes:
    - intelowl_postgres_data:/var/lib/postgresql/data
    - ./intelowl/sql_init:/docker-entrypoint-initdb.d
    networks:
      bev_osint:
        ipv4_address: 172.21.0.18
    logging: *id001
  intelowl-celery-beat:
    image: intelowlproject/intelowl:v5.2.0
    platform: linux/amd64
    container_name: bev_intelowl_celery_beat
    restart: always
    depends_on:
    - intelowl-postgres
    - redis
    - rabbitmq-1
    environment:
    - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
    - POSTGRES_HOST=${INTELOWL_POSTGRES_HOST}
    - POSTGRES_DB=${INTELOWL_POSTGRES_DB}
    - POSTGRES_USER=${INTELOWL_POSTGRES_USER}
    - POSTGRES_PASSWORD=${INTELOWL_POSTGRES_PASSWORD}
    - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
    - CELERY_BROKER_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-1:5672
    - DISABLE_AUTHENTICATION_CHECKS=True
    - DISABLE_PERMISSIONS_CHECKS=True
    - DISABLE_THROTTLING=True
    volumes:
    - ./intelowl/custom_analyzers:/opt/deploy/intelowl/custom_analyzers:ro
    - ./intelowl/custom_connectors:/opt/deploy/intelowl/custom_connectors:ro
    - /home/starlord/Bev/src:/opt/bev_src:ro
    - intelowl_static_data:/opt/deploy/static
    - logs:/var/log/intelowl
    command: celery -A intel_owl beat -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    networks:
      bev_osint:
        ipv4_address: 172.21.0.19
    logging: *id001
  intelowl-celery-worker:
    image: intelowlproject/intelowl:v5.2.0
    platform: linux/amd64
    restart: always
    depends_on:
    - intelowl-postgres
    - redis
    - rabbitmq-1
    environment:
    - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
    - POSTGRES_HOST=${INTELOWL_POSTGRES_HOST}
    - POSTGRES_DB=${INTELOWL_POSTGRES_DB}
    - POSTGRES_USER=${INTELOWL_POSTGRES_USER}
    - POSTGRES_PASSWORD=${INTELOWL_POSTGRES_PASSWORD}
    - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
    - CELERY_BROKER_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-1:5672
    - DISABLE_AUTHENTICATION_CHECKS=True
    - DISABLE_PERMISSIONS_CHECKS=True
    - DISABLE_THROTTLING=True
    - HTTP_PROXY=socks5://tor:9050
    - HTTPS_PROXY=socks5://tor:9050
    - TOR_PROXY=${TOR_PROXY}
    - NEO4J_URI=${NEO4J_URI}
    - NEO4J_USER=${NEO4J_USER}
    - NEO4J_PASSWORD=${NEO4J_PASSWORD}
    - DEHASHED_API_KEY=${DEHASHED_API_KEY}
    - DEHASHED_EMAIL=${DEHASHED_EMAIL}
    - SNUSBASE_API_KEY=${SNUSBASE_API_KEY}
    - WELEAKINFO_API_KEY=${WELEAKINFO_API_KEY}
    - SHODAN_API_KEY=${SHODAN_API_KEY}
    - VIRUSTOTAL_API_KEY=${VIRUSTOTAL_API_KEY}
    volumes:
    - ./intelowl/custom_analyzers:/opt/deploy/intelowl/custom_analyzers:ro
    - ./intelowl/custom_connectors:/opt/deploy/intelowl/custom_connectors:ro
    - /home/starlord/Bev/src:/opt/bev_src:ro
    - intelowl_static_data:/opt/deploy/static
    - logs:/var/log/intelowl
    command: celery -A intel_owl worker -l info -c ${WORKERS} --max-tasks-per-child
      100
    networks:
      bev_osint:
        ipv4_address: 172.21.0.20
    logging: *id001
    deploy:
      replicas: 4
      resources:
        limits:
          memory: 4G
  intelowl-django:
    image: intelowlproject/intelowl:v5.2.0
    platform: linux/amd64
    container_name: bev_intelowl_django
    restart: always
    depends_on:
    - intelowl-postgres
    - redis
    - rabbitmq-1
    environment:
    - DJANGO_ALLOWED_HOSTS=0.0.0.0,*
    - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
    - POSTGRES_HOST=${INTELOWL_POSTGRES_HOST}
    - POSTGRES_DB=${INTELOWL_POSTGRES_DB}
    - POSTGRES_USER=${INTELOWL_POSTGRES_USER}
    - POSTGRES_PASSWORD=${INTELOWL_POSTGRES_PASSWORD}
    - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
    - CELERY_BROKER_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-1:5672
    - DISABLE_AUTHENTICATION_CHECKS=True
    - DISABLE_PERMISSIONS_CHECKS=True
    - DISABLE_THROTTLING=True
    - DJANGO_ALLOWED_HOSTS=${DJANGO_ALLOWED_HOSTS}
    - DJANGO_DEBUG=${DJANGO_DEBUG}
    - DEFAULT_FROM_EMAIL=bev-osint@localhost
    - DEFAULT_EMAIL=bev@localhost
    volumes:
    - ./intelowl/custom_analyzers:/opt/deploy/intelowl/custom_analyzers:ro
    - ./intelowl/custom_connectors:/opt/deploy/intelowl/custom_connectors:ro
    - /home/starlord/Bev/src:/opt/bev_src:ro
    - intelowl_static_data:/opt/deploy/static
    - ./intelowl/dark_theme.css:/opt/deploy/static/css/custom.css:ro
    - logs:/var/log/intelowl
    command: 'sh -c " python manage.py migrate && python manage.py collectstatic --noinput
      && python manage.py createsuperuser --noinput --username admin --email admin@localhost
      || true && gunicorn intel_owl.wsgi:application --bind 0.0.0.0:8000 --workers
      ${WORKERS} --threads ${THREADS_PER_WORKER} --timeout ${REQUEST_TIMEOUT} --access-logfile
      - --error-logfile -"

      '
    ports:
    - 8000:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.21
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/api/health
      interval: 30s
      timeout: 10s
      retries: 5
  intelowl-nginx:
    image: nginx:alpine
    container_name: bev_intelowl_nginx
    restart: always
    depends_on:
    - intelowl-django
    volumes:
    - ./intelowl/nginx.conf:/etc/nginx/nginx.conf:ro
    - intelowl_static_data:/usr/share/nginx/html/static:ro
    - ./cytoscape:/usr/share/nginx/html/cytoscape:ro
    - ./intelowl/dark_theme.css:/usr/share/nginx/html/static/css/dark_theme.css:ro
    - logs:/var/log/nginx
    ports:
    - 80:80
    - 443:443
    networks:
      bev_osint:
        ipv4_address: 172.21.0.22
    logging: *id001
    healthcheck:
      test:
      - CMD
      - wget
      - --no-verbose
      - --tries=1
      - --spider
      - http://localhost:80
      interval: 30s
      timeout: 10s
      retries: 5
  cytoscape-server:
    build:
      context: ./cytoscape
      dockerfile: Dockerfile
    container_name: bev_cytoscape_server
    restart: always
    depends_on:
    - neo4j
    - postgres
    environment:
      NODE_ENV: production
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      POSTGRES_URI: ${POSTGRES_URI}
      PORT: 3000
    volumes:
    - ./cytoscape:/app
    - logs:/app/logs
    ports:
    - 3000:3000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.23
    logging: *id001
  prometheus:
    image: prom/prometheus:v2.47.0
    platform: linux/amd64
    container_name: bev_prometheus
    restart: always
    command:
    - --config.file=/etc/prometheus/prometheus.yml
    - --storage.tsdb.path=/prometheus
    - --web.console.libraries=/etc/prometheus/console_libraries
    - --web.console.templates=/etc/prometheus/consoles
    - --storage.tsdb.retention.time=30d
    - --web.enable-lifecycle
    - --web.enable-admin-api
    volumes:
    - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    - ./prometheus/rules:/etc/prometheus/rules:ro
    - prometheus_data:/prometheus
    - logs:/var/log/prometheus
    environment:
    - --web.listen-address=0.0.0.0:9090
    ports:
    - 9090:9090
    networks:
      bev_osint:
        ipv4_address: 172.21.0.24
    logging: *id001
    healthcheck:
      test:
      - CMD
      - wget
      - --no-verbose
      - --tries=1
      - --spider
      - http://localhost:9090/-/healthy
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
  grafana:
    image: grafana/grafana:10.2.0
    platform: linux/amd64
    container_name: bev_grafana
    restart: always
    environment:
      GF_SERVER_HTTP_ADDR: 0.0.0.0
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource,grafana-worldmap-panel
      GF_PATHS_PROVISIONING: /etc/grafana/provisioning
      GF_ANALYTICS_REPORTING_ENABLED: 'false'
      GF_ANALYTICS_CHECK_FOR_UPDATES: 'false'
      GF_LOG_LEVEL: warn
    volumes:
    - grafana_data:/var/lib/grafana
    - ./grafana/provisioning:/etc/grafana/provisioning:ro
    - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    - logs:/var/log/grafana
    ports:
    - 3001:3000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.25
    logging: *id001
    healthcheck:
      test:
      - CMD-SHELL
      - wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit
        1
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
  node-exporter:
    image: prom/node-exporter:v1.6.1
    platform: linux/amd64
    container_name: bev_node_exporter
    restart: always
    command:
    - --path.procfs=/host/proc
    - --path.rootfs=/rootfs
    - --path.sysfs=/host/sys
    - --collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)
    volumes:
    - /proc:/host/proc:ro
    - /sys:/host/sys:ro
    - /:/rootfs:ro
    ports:
    - 9100:9100
    networks:
      bev_osint:
        ipv4_address: 172.21.0.26
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 256M
  airflow-scheduler:
    image: apache/airflow:2.7.2-python3.11
    platform: linux/amd64
    container_name: bev_airflow_scheduler
    restart: always
    depends_on:
    - postgres
    - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      AIRFLOW__CELERY__RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/2
      AIRFLOW__CELERY__BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/2
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.basic_auth
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      AIRFLOW__METRICS__STATSD_ON: 'true'
      AIRFLOW__METRICS__STATSD_HOST: prometheus
      AIRFLOW__METRICS__STATSD_PORT: 8125
    volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./airflow/config:/opt/airflow/config
    - logs:/var/log/airflow
    command: scheduler
    networks:
      bev_osint:
        ipv4_address: 172.21.0.27
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 2G
  airflow-webserver:
    image: apache/airflow:2.7.2-python3.11
    platform: linux/amd64
    container_name: bev_airflow_webserver
    restart: always
    depends_on:
    - postgres
    - redis
    - airflow-scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      AIRFLOW__CELERY__RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/2
      AIRFLOW__CELERY__BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/2
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.basic_auth
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      AIRFLOW_ADMIN_USER: ${AIRFLOW_ADMIN_USER:-admin}
      AIRFLOW_ADMIN_PASSWORD: ${AIRFLOW_ADMIN_PASSWORD}
      AIRFLOW_ADMIN_EMAIL: ${AIRFLOW_ADMIN_EMAIL:-admin@bev.local}
    volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./airflow/config:/opt/airflow/config
    - logs:/var/log/airflow
    ports:
    - 8080:8080
    command: webserver
    networks:
      bev_osint:
        ipv4_address: 172.21.0.28
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8080/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
  airflow-worker-1:
    image: apache/airflow:2.7.2-python3.11
    platform: linux/amd64
    container_name: bev_airflow_worker_1
    restart: always
    depends_on:
    - postgres
    - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      AIRFLOW__CELERY__RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/2
      AIRFLOW__CELERY__BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/2
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CELERY__WORKER_CONCURRENCY: 4
    volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./airflow/config:/opt/airflow/config
    - logs:/var/log/airflow
    command: celery worker
    networks:
      bev_osint:
        ipv4_address: 172.21.0.29
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 3G
  airflow-worker-2:
    image: apache/airflow:2.7.2-python3.11
    platform: linux/amd64
    container_name: bev_airflow_worker_2
    restart: always
    depends_on:
    - postgres
    - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      AIRFLOW__CELERY__RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/2
      AIRFLOW__CELERY__BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/2
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CELERY__WORKER_CONCURRENCY: 4
    volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./airflow/config:/opt/airflow/config
    - logs:/var/log/airflow
    command: celery worker
    networks:
      bev_osint:
        ipv4_address: 172.21.0.30
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 3G
  airflow-worker-3:
    image: apache/airflow:2.7.2-python3.11
    platform: linux/amd64
    container_name: bev_airflow_worker_3
    restart: always
    depends_on:
    - postgres
    - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      AIRFLOW__CELERY__RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/2
      AIRFLOW__CELERY__BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/2
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CELERY__WORKER_CONCURRENCY: 4
    volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ./airflow/plugins:/opt/airflow/plugins
    - ./airflow/config:/opt/airflow/config
    - logs:/var/log/airflow
    command: celery worker
    networks:
      bev_osint:
        ipv4_address: 172.21.0.31
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 3G
  ocr-service:
    build:
      context: ./thanos/phase2/ocr
      dockerfile: Dockerfile
    container_name: bev_ocr_service
    restart: always
    depends_on:
    - redis
    - postgres
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/3
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      OCR_WORKERS: 4
      TESSDATA_PREFIX: /usr/share/tesseract-ocr/5/tessdata
      MAX_FILE_SIZE: 50MB
      SUPPORTED_FORMATS: pdf,png,jpg,jpeg,tiff,webp
    volumes:
    - ocr_data:/app/data
    - ./thanos/phase2/ocr/tessdata:/usr/share/tesseract-ocr/5/tessdata:ro
    - logs:/var/log/ocr
    ports:
    - 8001:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.32
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
  doc-analyzer-1:
    build:
      context: ./thanos/phase2/analyzer
      dockerfile: Dockerfile
    container_name: bev_doc_analyzer_1
    runtime: nvidia
    restart: always
    depends_on:
    - redis
    - postgres
    - elasticsearch
    - neo4j
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/3
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      ELASTICSEARCH_URL: http://elasticsearch:9200
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      WORKER_ID: 1
      CONCURRENT_JOBS: 3
      NLP_MODEL: en_core_web_sm
      ENABLE_GPU: 'true'
    volumes:
    - document_analyzer_data:/app/data
    - ./thanos/phase2/analyzer/models:/app/models:ro
    - logs:/var/log/analyzer
    networks:
      bev_osint:
        ipv4_address: 172.21.0.33
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 6G
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities:
            - gpu
  doc-analyzer-2:
    build:
      context: ./thanos/phase2/analyzer
      dockerfile: Dockerfile
    container_name: bev_doc_analyzer_2
    runtime: nvidia
    restart: always
    depends_on:
    - redis
    - postgres
    - elasticsearch
    - neo4j
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/3
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      ELASTICSEARCH_URL: http://elasticsearch:9200
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      WORKER_ID: 2
      CONCURRENT_JOBS: 3
      NLP_MODEL: en_core_web_sm
      ENABLE_GPU: 'true'
    volumes:
    - document_analyzer_data:/app/data
    - ./thanos/phase2/analyzer/models:/app/models:ro
    - logs:/var/log/analyzer
    networks:
      bev_osint:
        ipv4_address: 172.21.0.34
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 6G
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities:
            - gpu
  doc-analyzer-3:
    build:
      context: ./thanos/phase2/analyzer
      dockerfile: Dockerfile
    container_name: bev_doc_analyzer_3
    runtime: nvidia
    restart: always
    depends_on:
    - redis
    - postgres
    - elasticsearch
    - neo4j
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/3
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      ELASTICSEARCH_URL: http://elasticsearch:9200
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      WORKER_ID: 3
      CONCURRENT_JOBS: 3
      NLP_MODEL: en_core_web_sm
      ENABLE_GPU: 'true'
    volumes:
    - document_analyzer_data:/app/data
    - ./thanos/phase2/analyzer/models:/app/models:ro
    - logs:/var/log/analyzer
    networks:
      bev_osint:
        ipv4_address: 172.21.0.35
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 6G
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities:
            - gpu
  swarm-master-1:
    build:
      context: ./thanos/phase3/swarm
      dockerfile: Dockerfile
    container_name: bev_swarm_master_1
    runtime: nvidia
    restart: always
    depends_on:
    - redis
    - postgres
    - neo4j
    - kafka-1
    environment:
      SWARM_ID: master-1
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/4
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      SWARM_ROLE: master
      MAX_AGENTS: 50
      COORDINATION_STRATEGY: democratic
      CONSENSUS_THRESHOLD: 0.7
    volumes:
    - swarm_data:/app/data
    - ./thanos/phase3/swarm/strategies:/app/strategies:ro
    - logs:/var/log/swarm
    ports:
    - 8002:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.36
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities:
            - gpu
  swarm-master-2:
    build:
      context: ./thanos/phase3/swarm
      dockerfile: Dockerfile
    container_name: bev_swarm_master_2
    runtime: nvidia
    restart: always
    depends_on:
    - redis
    - postgres
    - neo4j
    - kafka-1
    environment:
      SWARM_ID: master-2
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/4
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      SWARM_ROLE: master
      MAX_AGENTS: 50
      COORDINATION_STRATEGY: hierarchical
      CONSENSUS_THRESHOLD: 0.7
    volumes:
    - swarm_data:/app/data
    - ./thanos/phase3/swarm/strategies:/app/strategies:ro
    - logs:/var/log/swarm
    ports:
    - 8003:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.37
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities:
            - gpu
  research-coordinator:
    build:
      context: ./thanos/phase3/coordinator
      dockerfile: Dockerfile
    container_name: bev_research_coordinator
    restart: always
    depends_on:
    - redis
    - postgres
    - neo4j
    - elasticsearch
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/5
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      ELASTICSEARCH_URL: http://elasticsearch:9200
      RESEARCH_DEPTH: advanced
      PARALLEL_STREAMS: 8
      CORRELATION_THRESHOLD: 0.6
      AUTO_PIVOT: 'true'
    volumes:
    - ./thanos/phase3/coordinator/research_templates:/app/templates:ro
    - logs:/var/log/coordinator
    ports:
    - 8004:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.38
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 3G
  memory-manager:
    build:
      context: ./thanos/phase3/memory
      dockerfile: Dockerfile
    container_name: bev_memory_manager
    restart: always
    depends_on:
    - redis
    - postgres
    - neo4j
    - elasticsearch
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/6
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      ELASTICSEARCH_URL: http://elasticsearch:9200
      MEMORY_RETENTION_DAYS: 365
      COMPRESSION_ENABLED: 'true'
      VECTOR_DIMENSIONS: 1536
      SIMILARITY_THRESHOLD: 0.8
    volumes:
    - memory_data:/app/data
    - ./thanos/phase3/memory/embeddings:/app/embeddings:ro
    - logs:/var/log/memory
    ports:
    - 8005:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.39
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 8G
  code-optimizer:
    build:
      context: ./thanos/phase3/optimizer
      dockerfile: Dockerfile
    container_name: bev_code_optimizer
    restart: always
    depends_on:
    - redis
    - postgres
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/7
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      OPTIMIZATION_LEVEL: aggressive
      PARALLEL_JOBS: 6
      AUTO_REFACTOR: 'true'
      SAFETY_CHECKS: 'true'
      BACKUP_ENABLED: 'true'
    volumes:
    - code_data:/app/data
    - ./thanos/phase3/optimizer/templates:/app/templates:ro
    - /home/starlord/Bev/src:/app/source:rw
    - logs:/var/log/optimizer
    ports:
    - 8006:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.40
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
  tool-coordinator:
    build:
      context: ./thanos/phase3/tools
      dockerfile: Dockerfile
    container_name: bev_tool_coordinator
    restart: always
    depends_on:
    - redis
    - postgres
    - neo4j
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/8
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      TOOL_REGISTRY_URL: http://0.0.0.0:8007/tools
      AUTO_DISCOVERY: 'true'
      HEALTH_CHECK_INTERVAL: 60
      LOAD_BALANCING: round_robin
    volumes:
    - tool_data:/app/data
    - ./thanos/phase3/tools/registry:/app/registry:ro
    - logs:/var/log/tools
    ports:
    - 8007:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.41
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
  guardian-enforcer-1:
    build:
      context: ./thanos/phase4/guardian
      dockerfile: Dockerfile
    container_name: bev_guardian_1
    restart: always
    depends_on:
    - redis
    - postgres
    environment:
      GUARDIAN_ID: enforcer-1
      VAULT_ADDR: http://100.122.12.35:8200
      VAULT_TOKEN: ${VAULT_ROOT_TOKEN}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/9
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      SECURITY_LEVEL: high
      MONITORING_MODE: active
      THREAT_RESPONSE: automatic
      INCIDENT_ESCALATION: 'true'
    volumes:
    - guardian_data:/app/data
    - ./thanos/phase4/guardian/rules:/app/rules:ro
    - logs:/var/log/guardian
    ports:
    - 8008:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.43
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
  guardian-enforcer-2:
    build:
      context: ./thanos/phase4/guardian
      dockerfile: Dockerfile
    container_name: bev_guardian_2
    restart: always
    depends_on:
    - redis
    - postgres
    environment:
      GUARDIAN_ID: enforcer-2
      VAULT_ADDR: http://100.122.12.35:8200
      VAULT_TOKEN: ${VAULT_ROOT_TOKEN}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/9
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      SECURITY_LEVEL: high
      MONITORING_MODE: active
      THREAT_RESPONSE: automatic
      INCIDENT_ESCALATION: 'true'
    volumes:
    - guardian_data:/app/data
    - ./thanos/phase4/guardian/rules:/app/rules:ro
    - logs:/var/log/guardian
    ports:
    - 8009:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.44
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
  tor-node-1:
    image: torproject/tor:latest
    platform: linux/amd64
    container_name: bev_tor_node_1
    restart: always
    environment:
      TOR_NICKNAME: BevNode1
      TOR_RELAY_PORT: 9001
      TOR_DIR_PORT: 9030
      TOR_BANDWIDTH_RATE: 100MB
      TOR_BANDWIDTH_BURST: 200MB
    volumes:
    - tor_nodes_data:/var/lib/tor
    - ./thanos/phase4/tor/node1.conf:/etc/tor/torrc:ro
    - logs:/var/log/tor
    ports:
    - 9001:9001
    - 9030:9030
    networks:
      bev_osint:
        ipv4_address: 172.21.0.45
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 512M
  tor-node-2:
    image: torproject/tor:latest
    platform: linux/amd64
    container_name: bev_tor_node_2
    restart: always
    environment:
      TOR_NICKNAME: BevNode2
      TOR_RELAY_PORT: 9002
      TOR_DIR_PORT: 9031
      TOR_BANDWIDTH_RATE: 100MB
      TOR_BANDWIDTH_BURST: 200MB
    volumes:
    - tor_nodes_data:/var/lib/tor
    - ./thanos/phase4/tor/node2.conf:/etc/tor/torrc:ro
    - logs:/var/log/tor
    ports:
    - 9002:9002
    - 9031:9031
    networks:
      bev_osint:
        ipv4_address: 172.21.0.46
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 512M
  tor-node-3:
    image: torproject/tor:latest
    platform: linux/amd64
    container_name: bev_tor_node_3
    restart: always
    environment:
      TOR_NICKNAME: BevNode3
      TOR_RELAY_PORT: 9003
      TOR_DIR_PORT: 9032
      TOR_BANDWIDTH_RATE: 100MB
      TOR_BANDWIDTH_BURST: 200MB
    volumes:
    - tor_nodes_data:/var/lib/tor
    - ./thanos/phase4/tor/node3.conf:/etc/tor/torrc:ro
    - logs:/var/log/tor
    ports:
    - 9003:9003
    - 9032:9032
    networks:
      bev_osint:
        ipv4_address: 172.21.0.47
    logging: *id001
    deploy:
      resources:
        limits:
          memory: 512M
  ids:
    build:
      context: ./thanos/phase4/ids
      dockerfile: Dockerfile
    container_name: bev_ids
    restart: always
    depends_on:
    - redis
    - postgres
    - elasticsearch
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/10
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      ELASTICSEARCH_URL: http://elasticsearch:9200
      IDS_MODE: active
      ALERT_THRESHOLD: medium
      AUTO_BLOCK: 'true'
      WHITELIST_ENABLED: 'true'
      ML_DETECTION: 'true'
    volumes:
    - ids_data:/app/data
    - ./thanos/phase4/ids/rules:/app/rules:ro
    - security_logs:/var/log/ids
    ports:
    - 8010:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.48
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
  traffic-analyzer:
    build:
      context: ./thanos/phase4/traffic
      dockerfile: Dockerfile
    container_name: bev_traffic_analyzer
    restart: always
    depends_on:
    - redis
    - postgres
    - influxdb
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/11
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      INFLUXDB_URL: http://influxdb:8086
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}
      ANALYSIS_MODE: realtime
      PACKET_CAPTURE: 'true'
      DPI_ENABLED: 'true'
      GEOLOCATION: 'true'
    volumes:
    - ./thanos/phase4/traffic/captures:/app/captures
    - security_logs:/var/log/traffic
    ports:
    - 8011:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.49
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 6G
  anomaly-detector:
    build:
      context: ./thanos/phase4/anomaly
      dockerfile: Dockerfile
    container_name: bev_anomaly_detector
    restart: always
    depends_on:
    - redis
    - postgres
    - elasticsearch
    - influxdb
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/12
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      ELASTICSEARCH_URL: http://elasticsearch:9200
      INFLUXDB_URL: http://influxdb:8086
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}
      ML_MODEL: isolation_forest
      SENSITIVITY: high
      REAL_TIME: 'true'
      AUTO_LEARNING: 'true'
    volumes:
    - ./thanos/phase4/anomaly/models:/app/models
    - security_logs:/var/log/anomaly
    ports:
    - 8012:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.50
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 8G
  autonomous-controller-1:
    build:
      context: ./thanos/phase5/controller
      dockerfile: Dockerfile
    container_name: bev_autonomous_1
    restart: always
    depends_on:
    - redis
    - postgres
    - neo4j
    environment:
      CONTROLLER_ID: autonomous-1
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/13
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      VAULT_ADDR: http://100.122.12.35:8200
      VAULT_TOKEN: ${VAULT_ROOT_TOKEN}
      AUTONOMY_LEVEL: supervised
      DECISION_CONFIDENCE: 0.85
      LEARNING_RATE: adaptive
      SAFETY_OVERRIDE: 'true'
    volumes:
    - autonomous_data:/app/data
    - ./thanos/phase5/controller/policies:/app/policies:ro
    - logs:/var/log/autonomous
    ports:
    - 8013:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.51
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 6G
  autonomous-controller-2:
    build:
      context: ./thanos/phase5/controller
      dockerfile: Dockerfile
    container_name: bev_autonomous_2
    restart: always
    depends_on:
    - redis
    - postgres
    - neo4j
    environment:
      CONTROLLER_ID: autonomous-2
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/13
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
      VAULT_ADDR: http://100.122.12.35:8200
      VAULT_TOKEN: ${VAULT_ROOT_TOKEN}
      AUTONOMY_LEVEL: supervised
      DECISION_CONFIDENCE: 0.85
      LEARNING_RATE: adaptive
      SAFETY_OVERRIDE: 'true'
    volumes:
    - autonomous_data:/app/data
    - ./thanos/phase5/controller/policies:/app/policies:ro
    - logs:/var/log/autonomous
    ports:
    - 8014:8000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.52
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 6G
  live2d-avatar:
    build:
      context: ./thanos/phase5/live2d/backend
      dockerfile: Dockerfile
    container_name: bev_live2d_avatar
    restart: always
    depends_on:
    - redis
    - postgres
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/14
      POSTGRES_URI: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/osint
      AVATAR_MODEL: bev_model_v1
      VOICE_ENGINE: espeak
      TTS_VOICE: en-us
      EMOTION_ENGINE: facial_expressions
      GESTURE_SYNC: 'true'
      REAL_TIME_RESPONSE: 'true'
    volumes:
    - live2d_data:/app/data
    - avatar_assets:/app/assets
    - ./thanos/phase5/live2d/models:/app/models:ro
    - logs:/var/log/live2d
    ports:
    - 8015:8000
    - 9001:9001
    networks:
      bev_osint:
        ipv4_address: 172.21.0.53
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8000/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
  live2d-frontend:
    build:
      context: ./thanos/phase5/live2d/frontend
      dockerfile: Dockerfile
    container_name: bev_live2d_frontend
    restart: always
    depends_on:
    - live2d-avatar
    environment:
      NODE_ENV: production
      REACT_APP_AVATAR_API: http://172.21.0.53:8000
      REACT_APP_WEBSOCKET_URL: ws://172.21.0.53:9001
      REACT_APP_TITLE: Bev - OSINT Intelligence Avatar
      GENERATE_SOURCEMAP: 'false'
    volumes:
    - ./thanos/phase5/live2d/frontend/public:/app/public
    - logs:/var/log/frontend
    ports:
    - 3002:3000
    networks:
      bev_osint:
        ipv4_address: 172.21.0.54
    logging: *id001
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:3000
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
