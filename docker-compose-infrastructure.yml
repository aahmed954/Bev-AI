version: '3.9'

x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"

networks:
  bev_osint:
    external: true

volumes:
  # Vector Database Volumes
  qdrant_data:
  weaviate_data:
  qdrant_snapshots:
  weaviate_backups:
  # Context Compression Volumes
  context_compression_data:
  compression_cache:
  # Health Monitoring Volumes
  health_monitoring_data:
  health_metrics_data:
  # Proxy Management Volumes
  proxy_pool_data:
  proxy_metrics_data:
  # Auto-Recovery Volumes
  recovery_logs_data:
  recovery_state_data:
  # Extended Reasoning Volumes
  extended_reasoning_data:
  extended_reasoning_cache:
  extended_reasoning_models:
  # Chaos Engineering Volumes
  chaos_logs_data:
  chaos_scenarios_data:
  # Edge Computing Volumes
  edge_models_us_east:
  edge_models_us_west:
  edge_models_eu_central:
  edge_models_asia_pacific:
  edge_cache_data:
  edge_logs_data:

services:
  # =============================================================
  # FOUNDATION LAYER - Vector Databases
  # =============================================================

  # Qdrant Primary Vector Database
  qdrant-primary:
    image: qdrant/qdrant:v1.6.1
    container_name: bev_qdrant_primary
    restart: unless-stopped

    environment:
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__CLUSTER__ENABLED: true
      QDRANT__CLUSTER__NODE_ID: 1
      QDRANT__CLUSTER__P2P__PORT: 6335
      QDRANT__LOG_LEVEL: INFO
      QDRANT__STORAGE__STORAGE_PATH: /qdrant/storage
      QDRANT__STORAGE__SNAPSHOTS_PATH: /qdrant/snapshots
      QDRANT__STORAGE__WAL_CAPACITY_MB: 32
      QDRANT__STORAGE__WAL_SEGMENTS_AHEAD: 0
      QDRANT__SERVICE__MAX_REQUEST_SIZE_MB: 32
      QDRANT__CLUSTER__CONSENSUS_TIMEOUT_MS: 1000

    volumes:
      - qdrant_data:/qdrant/storage
      - qdrant_snapshots:/qdrant/snapshots
      - ./config/qdrant:/qdrant/config:ro

    ports:
      - "6333:6333"  # HTTP API
      - "6334:6334"  # gRPC API
      - "6335:6335"  # P2P Port

    networks:
      bev_osint:
        ipv4_address: 172.30.0.36

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    labels:
      - "bev.component=vector-database"
      - "bev.service=qdrant-primary"
      - "bev.criticality=high"
      - "bev.category=infrastructure"

  # Qdrant Replica Vector Database
  qdrant-replica:
    image: qdrant/qdrant:v1.6.1
    container_name: bev_qdrant_replica
    restart: unless-stopped

    environment:
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__CLUSTER__ENABLED: true
      QDRANT__CLUSTER__NODE_ID: 2
      QDRANT__CLUSTER__P2P__PORT: 6335
      QDRANT__CLUSTER__BOOTSTRAP__PEER_IP: 172.30.0.36
      QDRANT__CLUSTER__BOOTSTRAP__PEER_PORT: 6335
      QDRANT__LOG_LEVEL: INFO
      QDRANT__STORAGE__STORAGE_PATH: /qdrant/storage
      QDRANT__STORAGE__SNAPSHOTS_PATH: /qdrant/snapshots
      QDRANT__STORAGE__WAL_CAPACITY_MB: 32
      QDRANT__STORAGE__WAL_SEGMENTS_AHEAD: 0
      QDRANT__SERVICE__MAX_REQUEST_SIZE_MB: 32
      QDRANT__CLUSTER__CONSENSUS_TIMEOUT_MS: 1000

    volumes:
      - qdrant_data:/qdrant/storage
      - qdrant_snapshots:/qdrant/snapshots
      - ./config/qdrant:/qdrant/config:ro

    ports:
      - "6343:6333"  # HTTP API (different port)
      - "6344:6334"  # gRPC API (different port)
      - "6345:6335"  # P2P Port (different port)

    networks:
      bev_osint:
        ipv4_address: 172.30.0.37

    depends_on:
      - qdrant-primary

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

    labels:
      - "bev.component=vector-database"
      - "bev.service=qdrant-replica"
      - "bev.criticality=high"
      - "bev.category=infrastructure"

  # Weaviate Vector Database
  weaviate:
    image: semitechnologies/weaviate:1.22.4
    container_name: bev_weaviate
    restart: unless-stopped

    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'false'
      AUTHENTICATION_APIKEY_ENABLED: 'true'
      AUTHENTICATION_APIKEY_ALLOWED_KEYS: ${WEAVIATE_API_KEY}
      AUTHENTICATION_APIKEY_USERS: 'admin'
      AUTHORIZATION_ADMINLIST_ENABLED: 'true'
      AUTHORIZATION_ADMINLIST_USERS: 'admin'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
      ENABLE_MODULES: 'text2vec-transformers,text2vec-openai,generative-openai,backup-filesystem'
      CLUSTER_HOSTNAME: 'node1'
      BACKUP_FILESYSTEM_PATH: '/var/lib/weaviate/backups'

    volumes:
      - weaviate_data:/var/lib/weaviate
      - weaviate_backups:/var/lib/weaviate/backups

    ports:
      - "8080:8080"

    networks:
      bev_osint:
        ipv4_address: 172.30.0.38

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/.well-known/ready"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

    labels:
      - "bev.component=vector-database"
      - "bev.service=weaviate"
      - "bev.criticality=high"
      - "bev.category=infrastructure"

  # Weaviate Transformers (T2V)
  weaviate-transformers:
    image: semitechnologies/transformers-inference:sentence-transformers-all-MiniLM-L6-v2
    container_name: bev_weaviate_transformers
    restart: unless-stopped

    environment:
      ENABLE_CUDA: 0

    networks:
      bev_osint:
        ipv4_address: 172.30.0.39

    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/.well-known/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    labels:
      - "bev.component=vector-database"
      - "bev.service=weaviate-transformers"
      - "bev.criticality=medium"
      - "bev.category=ml"

  # =============================================================
  # INFRASTRUCTURE LAYER - Core Services
  # =============================================================

  # Proxy Manager
  proxy-manager:
    build:
      context: .
      dockerfile: docker/proxy_management/Dockerfile.proxy_manager
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/proxy-manager:latest
    container_name: bev_proxy_manager
    restart: unless-stopped

    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - REDIS_DB=5
      - MAX_PROXIES_PER_POOL=50
      - HEALTH_CHECK_INTERVAL=300
      - RETRY_FAILED_INTERVAL=600
      - ROTATION_INTERVAL=3600
      - PERFORMANCE_WINDOW=86400
      - MIN_SUCCESS_RATE=0.7
      - MAX_RESPONSE_TIME=10.0
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - proxy_pool_data:/var/lib/proxy_pool
      - proxy_metrics_data:/var/lib/proxy_metrics
      - ./src/proxy_management:/app/src/proxy_management:ro
      - ./config:/app/config:ro

    ports:
      - "8040:8080"  # Management API
      - "9040:9090"  # Metrics endpoint

    networks:
      bev_osint:
        ipv4_address: 172.30.0.40

    external_links:
      - "postgres:postgres"
      - "redis-node-1:redis-node-1"

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    labels:
      - "bev.component=proxy-management"
      - "bev.service=proxy-manager"
      - "bev.criticality=high"
      - "bev.category=infrastructure"

  # Request Multiplexer
  request-multiplexer:
    build:
      context: .
      dockerfile: docker/request_multiplexing/Dockerfile.request_multiplexer
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/request-multiplexer:latest
    container_name: bev_request_multiplexer
    restart: unless-stopped

    environment:
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - REDIS_DB=6
      - MAX_CONCURRENT_REQUESTS=100
      - REQUEST_TIMEOUT=30
      - BATCH_SIZE=10
      - BATCH_TIMEOUT=1.0
      - RATE_LIMIT_PER_SECOND=50
      - CIRCUIT_BREAKER_THRESHOLD=5
      - CIRCUIT_BREAKER_TIMEOUT=60
      - PROXY_MANAGER_URL=http://proxy-manager:8080
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - ./src/request_multiplexing:/app/src/request_multiplexing:ro
      - ./config:/app/config:ro

    ports:
      - "8042:8080"  # API endpoint
      - "9042:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.42

    depends_on:
      - proxy-manager

    external_links:
      - "redis-node-1:redis-node-1"

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    labels:
      - "bev.component=request-multiplexing"
      - "bev.service=request-multiplexer"
      - "bev.criticality=high"
      - "bev.category=infrastructure"

  # Context Compressor
  context-compressor:
    build:
      context: .
      dockerfile: docker/context_compression/Dockerfile.context_compressor
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/context-compressor:latest
    container_name: bev_context_compressor
    restart: unless-stopped

    environment:
      - REDIS_HOST=redis-standalone
      - REDIS_PORT=6379
      - REDIS_DB=7
      - MAX_CONTEXT_SIZE=32768
      - COMPRESSION_RATIO_TARGET=0.3
      - CACHE_TTL=3600
      - MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
      - DEVICE=cpu
      - BATCH_SIZE=32
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - context_compression_data:/var/lib/context_compression
      - compression_cache:/var/cache/compression
      - ./src/context_compression:/app/src/context_compression:ro
      - ./config:/app/config:ro

    ports:
      - "8043:8080"  # API endpoint
      - "9043:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.43

    external_links:
      - "redis-standalone:redis-standalone"

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=context-compression"
      - "bev.service=context-compressor"
      - "bev.criticality=medium"
      - "bev.category=optimization"

  # =============================================================
  # MONITORING LAYER
  # =============================================================

  # Health Monitoring
  health-monitor:
    build:
      context: .
      dockerfile: docker/health_monitoring/Dockerfile.health_monitor
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/health-monitor:latest
    container_name: bev_health_monitor
    restart: unless-stopped

    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - REDIS_DB=8
      - CHECK_INTERVAL=30
      - ALERT_THRESHOLD_CRITICAL=5
      - ALERT_THRESHOLD_WARNING=3
      - RECOVERY_THRESHOLD=2
      - NOTIFICATION_COOLDOWN=300
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - health_monitoring_data:/var/lib/health_monitoring
      - health_metrics_data:/var/lib/health_metrics
      - ./src/health_monitoring:/app/src/health_monitoring:ro
      - ./config:/app/config:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro

    ports:
      - "8038:8080"  # Health API
      - "9038:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.38

    external_links:
      - "postgres:postgres"
      - "redis-node-1:redis-node-1"

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    labels:
      - "bev.component=health-monitoring"
      - "bev.service=health-monitor"
      - "bev.criticality=high"
      - "bev.category=monitoring"

  # Auto-Recovery Service
  auto-recovery:
    build:
      context: .
      dockerfile: docker/auto_recovery/Dockerfile.auto_recovery
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/auto-recovery:latest
    container_name: bev_auto_recovery
    restart: unless-stopped

    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - REDIS_DB=9
      - HEALTH_MONITOR_URL=http://health-monitor:8080
      - RECOVERY_CHECK_INTERVAL=60
      - MAX_RECOVERY_ATTEMPTS=3
      - RECOVERY_TIMEOUT=300
      - ESCALATION_THRESHOLD=5
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - recovery_logs_data:/var/lib/recovery_logs
      - recovery_state_data:/var/lib/recovery_state
      - ./src/auto_recovery:/app/src/auto_recovery:ro
      - ./config:/app/config:ro
      - /var/run/docker.sock:/var/run/docker.sock

    ports:
      - "8041:8080"  # Recovery API
      - "9041:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.41

    depends_on:
      - health-monitor

    external_links:
      - "postgres:postgres"
      - "redis-node-1:redis-node-1"

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=auto-recovery"
      - "bev.service=auto-recovery"
      - "bev.criticality=high"
      - "bev.category=automation"

  # Chaos Engineering
  chaos-engineer:
    build:
      context: .
      dockerfile: docker/chaos_engineering/Dockerfile.chaos_engineer
      args:
        - PYTHON_VERSION=3.11

    image: bev-osint/chaos-engineer:latest
    container_name: bev_chaos_engineer
    restart: unless-stopped

    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=bev_osint
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - REDIS_HOST=redis-node-1
      - REDIS_PORT=6379
      - REDIS_DB=10
      - EXPERIMENT_INTERVAL=3600
      - BLAST_RADIUS_LIMIT=0.1
      - AUTO_RECOVERY_ENABLED=true
      - HEALTH_MONITOR_URL=http://health-monitor:8080
      - RECOVERY_SERVICE_URL=http://auto-recovery:8080
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1

    volumes:
      - chaos_logs_data:/var/lib/chaos_logs
      - chaos_scenarios_data:/var/lib/chaos_scenarios
      - ./src/chaos_engineering:/app/src/chaos_engineering:ro
      - ./config:/app/config:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro

    ports:
      - "8045:8080"  # Chaos API
      - "9045:9090"  # Metrics

    networks:
      bev_osint:
        ipv4_address: 172.30.0.45

    depends_on:
      - health-monitor
      - auto-recovery

    external_links:
      - "postgres:postgres"
      - "redis-node-1:redis-node-1"

    logging: *default-logging

    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 120s

    labels:
      - "bev.component=chaos-engineering"
      - "bev.service=chaos-engineer"
      - "bev.criticality=low"
      - "bev.category=testing"