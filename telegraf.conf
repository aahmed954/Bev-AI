# Telegraf Configuration for ORACLE1 ARM Cloud Server
# BEV OSINT Framework - Monitoring and Metrics Collection

[global_tags]
  environment = "production"
  datacenter = "oracle1"
  platform = "arm64"
  region = "cloud"
  role = "distributed_worker"

[agent]
  interval = "30s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "5s"
  flush_interval = "30s"
  flush_jitter = "5s"
  precision = ""
  hostname = "oracle1-arm"
  omit_hostname = false

# OUTPUT PLUGINS

# InfluxDB output for local cluster
[[outputs.influxdb_v2]]
  urls = ["http://influxdb-primary:8086"]
  token = "${INFLUXDB_TOKEN}"
  organization = "bev"
  bucket = "oracle1_metrics"
  timeout = "30s"
  user_agent = "telegraf-oracle1"

# InfluxDB output for THANOS server (remote)
[[outputs.influxdb_v2]]
  urls = ["http://100.122.12.54:8086"]
  token = "${THANOS_INFLUXDB_TOKEN}"
  organization = "bev"
  bucket = "oracle1_remote_metrics"
  timeout = "60s"
  user_agent = "telegraf-oracle1-remote"

# INPUT PLUGINS

# System metrics optimized for ARM
[[inputs.cpu]]
  percpu = true
  totalcpu = true
  collect_cpu_time = false
  report_active = false

[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

[[inputs.diskio]]

[[inputs.kernel]]

[[inputs.mem]]

[[inputs.processes]]

[[inputs.swap]]

[[inputs.system]]

# Network metrics
[[inputs.net]]
  interfaces = ["eth*", "en*"]

[[inputs.netstat]]

# Docker containers monitoring
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
  gather_services = false
  container_names = []
  source_tag = false
  container_name_include = ["bev_*"]
  timeout = "30s"
  perdevice = true
  total = false
  docker_label_include = ["com.docker.compose.service", "com.docker.compose.project"]

# Redis monitoring for ARM instance
[[inputs.redis]]
  servers = ["tcp://redis-arm:6379"]
  password = ""
  pool_size = 2

# MinIO cluster monitoring
[[inputs.minio]]
  servers = [
    "http://minio1:9000",
    "http://minio2:9000", 
    "http://minio3:9000"
  ]
  access_key = "admin"
  secret_key = "${MINIO_PASSWORD}"
  secure = false
  buckets_include = []
  buckets_exclude = []

# InfluxDB monitoring (local cluster)
[[inputs.influxdb]]
  urls = [
    "http://influxdb-primary:8086/debug/vars",
    "http://influxdb-replica:8086/debug/vars"
  ]
  timeout = "30s"

# HTTP response monitoring for key services
[[inputs.http_response]]
  urls = [
    "http://n8n:5678/healthz",
    "http://n8n-advanced-1:5678/healthz",
    "http://n8n-advanced-2:5678/healthz", 
    "http://n8n-advanced-3:5678/healthz",
    "http://minio1:9000/minio/health/live",
    "http://minio2:9000/minio/health/live",
    "http://minio3:9000/minio/health/live",
    "http://litellm-gateway-1:4000/health",
    "http://litellm-gateway-2:4000/health",
    "http://litellm-gateway-3:4000/health",
    "http://request-multiplexer:8080/health",
    "http://influxdb-primary:8086/health",
    "http://influxdb-replica:8086/health"
  ]
  response_timeout = "30s"
  method = "GET"
  follow_redirects = false

# Nginx access logs parsing
[[inputs.logparser]]
  files = ["/var/log/nginx/access.log"]
  from_beginning = false
  watch_method = "inotify"

  [inputs.logparser.grok]
    patterns = ['''%{COMBINED_LOG_FORMAT} "?%{DATA:upstream_addr}"? "?%{DATA:upstream_response_time}"? "?%{DATA:request_time}"?''']
    measurement = "nginx_access_log"
    
# TCP port monitoring for service availability
[[inputs.net_response]]
  protocol = "tcp"
  address = "redis-arm:6379"
  timeout = "10s"

[[inputs.net_response]]
  protocol = "tcp"
  address = "minio1:9000"
  timeout = "10s"

[[inputs.net_response]]
  protocol = "tcp"
  address = "minio2:9000"
  timeout = "10s"

[[inputs.net_response]]
  protocol = "tcp"
  address = "minio3:9000"
  timeout = "10s"

# Custom metrics for BEV services
[[inputs.exec]]
  commands = ["/usr/local/bin/bev-metrics-collector.sh"]
  timeout = "30s"
  data_format = "influx"
  interval = "60s"

# Celery workers monitoring via Redis
[[inputs.redis]]
  servers = ["tcp://redis-arm:6379/0", "tcp://redis-arm:6379/1", "tcp://redis-arm:6379/2", "tcp://redis-arm:6379/3", "tcp://redis-arm:6379/4"]
  password = ""
  pool_size = 1
  
  [[inputs.redis.commands]]
    command = ["LLEN", "celery"]
    measurement = "celery_queue_length"

# ARM-specific CPU temperature monitoring (if available)
[[inputs.temp]]

# File descriptor monitoring for ARM optimization
[[inputs.linux_sysctl_fs]]

# Interrupt monitoring
[[inputs.interrupts]]

# Custom ARM performance counters
[[inputs.exec]]
  commands = ["cat /proc/stat | grep cpu"]
  timeout = "5s"
  data_format = "value"
  data_type = "string"
  name_override = "arm_cpu_stats"

# Network connection tracking
[[inputs.nstat]]
  proc_net_netstat = "/proc/net/netstat"
  proc_net_snmp = "/proc/net/snmp"
  proc_net_snmp6 = "/proc/net/snmp6"
  dump_zeros = true

# Process monitoring for key BEV services
[[inputs.procstat]]
  pattern = "n8n"
  pid_tag = true

[[inputs.procstat]]
  pattern = "minio"
  pid_tag = true

[[inputs.procstat]]
  pattern = "celery"
  pid_tag = true

# PROCESSOR PLUGINS

# Add hostname to metrics
[[processors.override]]
  [processors.override.tags]
    hostname = "oracle1-arm"
    server_type = "worker_node"
    
# Convert fields to appropriate types
[[processors.converter]]
  [processors.converter.fields]
    integer = ["cpu_usage_*", "memory_*", "disk_*"]
    float = ["response_time", "upstream_response_time", "request_time"]

# Calculate rates for counter metrics
[[processors.derivative]]
  variable = "time"
  suffix = "_rate"
  
# Add computed fields for ARM-specific metrics
[[processors.starlark]]
  script = '''
def apply(metric):
    if metric.name == "cpu":
        # ARM-specific CPU efficiency calculation
        if "usage_idle" in metric.fields:
            metric.fields["arm_efficiency"] = 100.0 - metric.fields["usage_idle"]
    return metric
'''

# AGGREGATOR PLUGINS

# Aggregate metrics for summary views
[[aggregators.basicstats]]
  period = "300s"
  drop_original = false
  stats = ["count", "min", "max", "mean", "stdev"]
  
[[aggregators.histogram]]
  period = "300s"
  drop_original = false
  buckets = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0]

# Final metric processing
[[processors.regex]]
  [[processors.regex.tags]]
    key = "container_name"
    pattern = "^bev_(.*)$"
    replacement = "${1}"
    result_key = "service_name"